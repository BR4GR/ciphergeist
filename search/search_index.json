{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"ciphergeistCIPHERGEIST","text":"<p>riddles and stuff</p> <p> </p> <p>Welcome, CipherGeist is my toolkit for exploring  cryptography.</p>"},{"location":"cryptopals/set1_basics/1_convert_hex_to_base64/","title":"Convert hex to base64","text":"<p>The string:</p> <pre><code>49276d206b696c6c696e6720796f757220627261696e206c696b65206120706f69736f6e6f7573206d757368726f6f6d\n</code></pre> <p>Should produce:</p> <pre><code>SSdtIGtpbGxpbmcgeW91ciBicmFpbiBsaWtlIGEgcG9pc29ub3VzIG11c2hyb29t\n</code></pre> <p>So go ahead and make that happen. You'll need to use this code for the rest of the exercises.</p> <p>Cryptopals Rule: Always operate on raw bytes, never on encoded strings. Only use hex and base64 for pretty-printing.</p>"},{"location":"cryptopals/set1_basics/1_convert_hex_to_base64/#solution","title":"Solution","text":"<pre><code>def convert_hex_to_base64(hex_string):\n    \"\"\"\n    Convert a hexadecimal string to a Base64 encoded string.\n\n    :param hex_string: A string representing a hexadecimal number.\n    :return: A Base64 encoded string.\n    \"\"\"\n    bytes_data = bytes.fromhex(hex_string)\n    base64_encoded = base64.b64encode(bytes_data)\n    return base64_encoded.decode('ascii')\n</code></pre> <pre><code>if __name__ == \"__main__\":\n    input_string = \"49276d206b696c6c696e6720796f757220627261696e206c696b65206120706f69736f6e6f7573206d757368726f6f6d\"\n    expectred_base64 = \"SSdtIGtpbGxpbmcgeW91ciBicmFpbiBsaWtlIGEgcG9pc29ub3VzIG11c2hyb29t\"\n    base64_string = convert_hex_to_base64(input_string)\n    print(f\"Base64 Encoded: {base64_string}\")\n    assert base64_string == expectred_base64, \"Conversion did not match expected output.\"\n    print(\"Conversion successful!\")\n    print(base64.b64decode(base64_string))\n</code></pre> <p>Base64 Encoded: SSdtIGtpbGxpbmcgeW91ciBicmFpbiBsaWtlIGEgcG9pc29ub3VzIG11c2hyb29t Conversion successful!</p> <p>b\"I'm killing your brain like a poisonous mushroom\"</p>"},{"location":"cryptopals/set1_basics/2_fixed_XOR/","title":"Fixed XOR","text":"<p>Write a function that takes two equal-length buffers and produces their XOR combination.</p> <p>If your function works properly, then when you feed it the string:</p> <pre><code>1c0111001f010100061a024b53535009181c\n</code></pre> <p>... after hex decoding, and when XOR'd against:</p> <pre><code>686974207468652062756c6c277320657965\n</code></pre> <p>... should produce:</p> <pre><code>746865206b696420646f6e277420706c6179\n</code></pre>"},{"location":"cryptopals/set1_basics/2_fixed_XOR/#solution","title":"Solution","text":"<pre><code>def fixed_xor(a: bytes, b: bytes) -&gt; bytes:\n    \"\"\"Perform a fixed XOR operation on two byte strings.\"\"\"\n    if len(a) != len(b):\n        raise ValueError(\"Input byte strings must be of the same length.\")\n    return bytes(x ^ y for x, y in zip(a, b))\n\na = bytes.fromhex(\"1c0111001f010100061a024b53535009181c\")\nb = bytes.fromhex(\"686974207468652062756c6c277320657965\")\nresult = fixed_xor(a, b)\nprint(result)\n</code></pre> <p>\"the kid don't play\"</p>"},{"location":"cryptopals/set1_basics/3_single_byte_XOR_cipher/","title":"Single-byte XOR cipher","text":"<p>The hex encoded string:</p> <pre><code>1b37373331363f78151b7f2b783431333d78397828372d363c78373e783a393b3736\n</code></pre> <p>... has been XOR'd against a single character. Find the key, decrypt the message.</p> <p>You can do this by hand. But don't: write code to do it for you.</p> <p>How? Devise some method for \"scoring\" a piece of English plaintext. Character frequency is a good metric. Evaluate each output and choose the one with the best score.</p>"},{"location":"cryptopals/set1_basics/3_single_byte_XOR_cipher/#solution","title":"Solution","text":""},{"location":"cryptopals/set1_basics/3_single_byte_XOR_cipher/#1-single-byte-xor-function","title":"1. Single-byte XOR Function","text":"<pre><code>def single_byte_xor(input_bytes: bytes, key: int) -&gt; bytes:\n    \"\"\"Perform a single-byte XOR operation on a byte string.\"\"\"\n    if not (0 &lt;= key &lt;= 255):\n        raise ValueError(\"Key must be int (0-255).\")\n    return bytes(b ^ key for b in input_bytes)\n</code></pre>"},{"location":"cryptopals/set1_basics/3_single_byte_XOR_cipher/#2-text-scoring-algorithm","title":"2. Text Scoring Algorithm","text":"<p>The scoring function uses English letter frequency analysis:</p> <pre><code>def score_text(text: bytes) -&gt; float:\n    \"\"\"Score a byte string based on letter frequency analysis.\"\"\"\n    # Count letter frequencies in the text\n    counts_text = Counter()\n    for letter in lowercase_frequencies:\n        counts_text[letter] = text.count(letter.encode())\n\n    total = sum(counts_text.values())\n    if total == 0:\n        return float(\"inf\")\n\n    # Calculate frequency differences from expected English frequencies\n    frequencies_text = {letter: counts_text[letter] / total for letter in lowercase_frequencies}\n    errors = {abs(lowercase_frequencies[letter] - frequencies_text[letter]) for letter in lowercase_frequencies}\n    score = sum(errors)\n    return score\n</code></pre> <p>The scoring compares the frequency of letters in the decrypted text against known English letter frequencies. A lower score indicates text that's more likely to be English.</p>"},{"location":"cryptopals/set1_basics/3_single_byte_XOR_cipher/#3-brute-force-key-guessing","title":"3. Brute Force Key Guessing","text":"<pre><code>def guess_single_key_xor(ciphertext: bytes) -&gt; Guess:\n    \"\"\"Guess the single-byte XOR key for a given ciphertext.\"\"\"\n    best_guess = Guess.empty()\n    for key in range(256):\n        current_guess = Guess(ciphertext, key)\n        best_guess = min(best_guess, current_guess)\n    return best_guess\n</code></pre>"},{"location":"cryptopals/set1_basics/3_single_byte_XOR_cipher/#4-optimized-quick-guess","title":"4. Optimized Quick Guess","text":"<p>For faster results, there's also a heuristic approach:</p> <pre><code>def quick_guess_single_byte_xor(ciphertext: bytes) -&gt; Guess:\n    \"\"\"Quickly guess a single-byte XOR key using frequency heuristics.\"\"\"\n    frequencies = Counter(ciphertext)\n    most_common_byte = frequencies.most_common(1)[0][0]\n    common_chars = set(\" etaoinshrdlu\")  # Most common English characters\n\n    best_guess = Guess.empty()\n    for char in common_chars:\n        current_guess = Guess(ciphertext, most_common_byte ^ ord(char))\n        best_guess = min(best_guess, current_guess)\n    return best_guess\n</code></pre> <p>This assumes the most frequent byte in the ciphertext corresponds to a common English character.</p>"},{"location":"cryptopals/set1_basics/4_detect_single_character_XOR/","title":"Detect single-character XOR","text":"<p>One of the 60-character strings in this file has been encrypted by single-character XOR.</p> <p>Find it.</p> <p>(Your code from #3 should help.)</p>"},{"location":"reference/SUMMARY/","title":"SUMMARY","text":"<ul> <li>ciphergeist<ul> <li>analyzers<ul> <li>example_usage</li> <li>text_analyzer</li> </ul> </li> <li>converter</li> <li>decrypters<ul> <li>rsa_decrypter</li> </ul> </li> <li>encoders<ul> <li>pixelator</li> </ul> </li> <li>encrypters<ul> <li>substitutor</li> <li>xorxer</li> </ul> </li> <li>exceptions</li> <li>frequencies<ul> <li>calculate_frequenzies</li> <li>lowercase_frequencies</li> <li>mixed_frequencies</li> <li>uppercase_frequencies</li> </ul> </li> </ul> </li> </ul>"},{"location":"reference/ciphergeist/","title":"Index","text":"<p>CipherGeist - Cryptographic utilities and riddles.</p> <p>A collection of cryptographic tools, encoders, and frequency analysis utilities.</p>"},{"location":"reference/ciphergeist/#ciphergeist.ChunkInfo","title":"<code>ChunkInfo</code>  <code>dataclass</code>","text":"<p>Information about a data chunk.</p> Source code in <code>src/ciphergeist/encoders/pixelator.py</code> <pre><code>@dataclass\nclass ChunkInfo:\n    \"\"\"Information about a data chunk.\"\"\"\n\n    chunk_id: int\n    image_name: str\n    data_bytes: int\n    chunk_hash: str\n</code></pre>"},{"location":"reference/ciphergeist/#ciphergeist.EncodingResult","title":"<code>EncodingResult</code>  <code>dataclass</code>","text":"<p>Result of document encoding process.</p> Source code in <code>src/ciphergeist/encoders/pixelator.py</code> <pre><code>@dataclass\nclass EncodingResult:\n    \"\"\"Result of document encoding process.\"\"\"\n\n    metadata_image: str\n    chunk_images: list[str]\n    total_size: int\n    chunk_count: int\n</code></pre>"},{"location":"reference/ciphergeist/#ciphergeist.Guess","title":"<code>Guess</code>  <code>dataclass</code>","text":"Source code in <code>src/ciphergeist/encrypters/xorxer.py</code> <pre><code>@dataclass(order=True)\nclass Guess:\n    score: float\n    key: int\n    ciphertext: bytes\n    plaintext: bytes\n\n    def __init__(self, ciphertext: bytes, key: int, is_empty: bool = False):\n        self.ciphertext = ciphertext\n        self.key = key\n        if is_empty:\n            self.plaintext = b\"\"\n            self.score = float(\"inf\")\n            return\n        self.plaintext = single_byte_xor(ciphertext, key)\n        self.score = score_text(self.plaintext)\n\n    @classmethod\n    def empty(cls) -&gt; \"Guess\":\n        \"\"\"Create an empty guess with infinite score for comparison.\"\"\"\n        return cls(b\"\", 0, is_empty=True)\n</code></pre>"},{"location":"reference/ciphergeist/#ciphergeist.Guess.empty","title":"<code>empty()</code>  <code>classmethod</code>","text":"<p>Create an empty guess with infinite score for comparison.</p> Source code in <code>src/ciphergeist/encrypters/xorxer.py</code> <pre><code>@classmethod\ndef empty(cls) -&gt; \"Guess\":\n    \"\"\"Create an empty guess with infinite score for comparison.\"\"\"\n    return cls(b\"\", 0, is_empty=True)\n</code></pre>"},{"location":"reference/ciphergeist/#ciphergeist.Pixelator","title":"<code>Pixelator</code>","text":"<p>Document-to-Image encoder with optional encryption and metadata management.</p> <p>Converts documents to image files with comprehensive metadata tracking and recovery capabilities. Supports optional XOR encryption.</p> Source code in <code>src/ciphergeist/encoders/pixelator.py</code> <pre><code>class Pixelator:\n    \"\"\"\n    Document-to-Image encoder with optional encryption and metadata management.\n\n    Converts documents to image files with comprehensive metadata\n    tracking and recovery capabilities. Supports optional XOR encryption.\n    \"\"\"\n\n    IMAGE_WIDTH = 160\n    IMAGE_HEIGHT = 125\n    IMAGE_CHANNELS = 3\n    ERROR_CORRECTION_RATIO = 0.2\n    CHUNK_OVERLAP_BYTES = 2**7  # 128 bytes overlap for error recovery\n\n    def __init__(self, encryption_key: Optional[str] = None) -&gt; None:\n        \"\"\"\n        Initialize Pixelator.\n\n        Args:\n            encryption_key: Optional XOR encryption key. If None, no encryption is used.\n        \"\"\"\n        self.encryption_key = encryption_key\n        self._magic = magic.Magic(mime=True)\n        self._http_client = httpx.AsyncClient(timeout=10.0)\n        self.image_capacity = self.IMAGE_WIDTH * self.IMAGE_HEIGHT * self.IMAGE_CHANNELS\n        self.chunk_size = self._calculate_optimal_chunk_size()\n\n    def _calculate_optimal_chunk_size(self) -&gt; int:\n        \"\"\"\n        Calculate the maximum data chunk size that can fit in an image\n        after accounting for recovery overhead.\n        \"\"\"\n        # Formula: Capacity = Chunk + (Chunk * ErrorRatio) + Overlap\n        # Rearranged: Capacity - Overlap = Chunk * (1 + ErrorRatio)\n        # Therefore: Chunk = (Capacity - Overlap) / (1 + ErrorRatio)\n\n        usable_capacity = self.image_capacity - self.CHUNK_OVERLAP_BYTES\n        optimal_size = usable_capacity / (1 + self.ERROR_CORRECTION_RATIO)\n\n        # Return as an integer, ensuring it's a multiple of 8 for clean boundaries\n        return int(optimal_size // 8 * 8)\n\n    def _xor_encrypt_decrypt(self, data: bytes, key: str) -&gt; bytes:\n        \"\"\"XOR encrypt/decrypt data with a repeating key.\"\"\"\n        if not key:\n            return data\n\n        key_bytes = key.encode(\"utf-8\")\n        result = bytearray()\n        key_len = len(key_bytes)\n\n        for i, byte in enumerate(data):\n            result.append(byte ^ key_bytes[i % key_len])\n\n        return bytes(result)\n\n    def _check_chunk_exists(self, chunk_path: Path, image_name: str) -&gt; None:\n        \"\"\"Check if chunk file exists and raise error if not.\"\"\"\n        if not chunk_path.exists():\n            raise FileNotFoundError(f\"Chunk image not found: {image_name}\")\n\n    def _verify_chunk_integrity(self, chunk_data: bytes, expected_hash: str, image_name: str) -&gt; None:\n        \"\"\"Verify chunk integrity and raise error if invalid.\"\"\"\n        chunk_hash = self._calculate_hash(chunk_data)\n        if chunk_hash != expected_hash:\n            raise ValueError(f\"Chunk integrity check failed: {image_name}\")\n\n    async def encode_document(\n        self, file_path: Union[str, Path], output_dir: Union[str, Path] = \"output\"\n    ) -&gt; EncodingResult:\n        \"\"\"\n        Encode document to images with optional encryption.\n\n        Args:\n            file_path: Path to document to encode\n            output_dir: Directory to save encoded images\n\n        Returns:\n            EncodingResult with metadata and image information\n\n        Raises:\n            FileNotFoundError: If input file doesn't exist\n            ValueError: If file cannot be processed\n        \"\"\"\n        file_path = Path(file_path)\n        output_dir = Path(output_dir)\n        output_dir.mkdir(exist_ok=True)\n\n        # Step 1: Process document\n        document_data, file_metadata = self._process_document(file_path)\n\n        # Step 2: Optionally encrypt data\n        if self.encryption_key:\n            encrypted_data = self._xor_encrypt_decrypt(document_data, self.encryption_key)\n        else:\n            encrypted_data = document_data\n\n        # Step 3: Create chunks\n        chunks = self._create_chunks(encrypted_data)\n\n        # Step 4: Generate image names\n        chunk_names = await self._generate_image_names(len(chunks))\n\n        # Create metadata image name based on document name\n        document_name = file_path.stem  # Get filename without extension\n        metadata_image_name = f\"{document_name}_metadata.png\"\n\n        # Step 5: Create chunk images\n        chunk_infos = []\n        chunk_images = []\n\n        for i, (chunk_data, filename) in enumerate(zip(chunks, chunk_names)):\n            chunk_hash = self._calculate_hash(chunk_data)\n            image_path = output_dir / filename\n\n            self._encode_data_to_image(chunk_data, image_path)\n\n            chunk_infos.append(\n                ChunkInfo(chunk_id=i, image_name=filename, data_bytes=len(chunk_data), chunk_hash=chunk_hash)\n            )\n            chunk_images.append(filename)\n\n        # Step 6: Create metadata\n        metadata = self._create_metadata(file_metadata, chunk_infos, encrypted_data)\n\n        # Step 7: Create metadata image\n        metadata_path = output_dir / metadata_image_name\n        metadata_json = json.dumps(metadata, indent=2).encode(\"utf-8\")\n\n        self._encode_data_to_image(metadata_json, metadata_path)\n\n        return EncodingResult(\n            metadata_image=metadata_image_name,\n            chunk_images=chunk_images,\n            total_size=len(encrypted_data),\n            chunk_count=len(chunks),\n        )\n\n    async def decode_document(\n        self,\n        metadata_image_path: Union[str, Path],\n        output_path: Union[str, Path],\n        images_dir: Optional[Union[str, Path]] = None,\n    ) -&gt; bool:\n        \"\"\"\n        Decode document from images with optional decryption.\n\n        Args:\n            metadata_image_path: Path to metadata image\n            output_path: Path where to save decoded document\n            images_dir: Directory containing chunk images (default: same as metadata)\n\n        Returns:\n            True if successful, False otherwise\n        \"\"\"\n        metadata_image_path = Path(metadata_image_path)\n        output_path = Path(output_path)\n\n        images_dir = metadata_image_path.parent if images_dir is None else Path(images_dir)\n\n        try:\n            # Step 1: Decode metadata\n            metadata_data = self._decode_data_from_image(metadata_image_path)\n            metadata = json.loads(metadata_data.decode(\"utf-8\"))\n\n            # Step 2: Collect chunks\n            chunks_data = []\n            chunk_infos = metadata[\"chunks\"][\"images\"]\n\n            for image_name, chunk_info in chunk_infos.items():\n                chunk_path = images_dir / image_name\n                self._check_chunk_exists(chunk_path, image_name)\n\n                chunk_data = self._decode_data_from_image(chunk_path)\n                expected_size = chunk_info[\"data_bytes\"]\n                chunk_data = chunk_data[:expected_size]  # Trim to exact size\n\n                # Verify chunk integrity\n                self._verify_chunk_integrity(chunk_data, chunk_info[\"chunk_hash\"], image_name)\n\n                chunks_data.append((chunk_info[\"chunk_id\"], chunk_data))\n\n            # Step 3: Reassemble data\n            chunks_data.sort(key=lambda x: x[0])  # Sort by chunk_id\n            assembled_data = b\"\".join(chunk[1] for chunk in chunks_data)\n\n            # Step 4: Optionally decrypt data\n            if self.encryption_key and metadata.get(\"encryption\", {}).get(\"algorithm\") == \"xor\":\n                document_data = self._xor_encrypt_decrypt(assembled_data, self.encryption_key)\n            else:\n                document_data = assembled_data\n\n            # Step 5: Decompress and save\n            original_data = lzma.decompress(document_data)\n            output_path.write_bytes(original_data)\n\n        except Exception as e:\n            print(f\"Decoding failed: {e}\")\n            return False\n        else:\n            return True\n\n    def _process_document(self, file_path: Path) -&gt; tuple[bytes, dict[str, Any]]:\n        \"\"\"Process document and generate metadata.\"\"\"\n        if not file_path.exists():\n            raise FileNotFoundError(f\"Document not found: {file_path}\")\n\n        original_data = file_path.read_bytes()\n        file_extension, mime_type = self._detect_file_type(file_path)\n        compressed_data = lzma.compress(original_data, preset=6)\n\n        metadata = {\n            \"filename\": file_path.name,\n            \"extension\": file_extension,\n            \"mime_type\": mime_type,\n            \"original_size\": len(original_data),\n            \"compressed_size\": len(compressed_data),\n            \"hash\": self._calculate_hash(original_data),\n        }\n\n        return compressed_data, metadata\n\n    def _detect_file_type(self, file_path: Path) -&gt; tuple[str, str]:\n        \"\"\"Detect file type and MIME type.\"\"\"\n        try:\n            mime_type = self._magic.from_file(str(file_path))\n        except Exception:\n            guessed_mime_type, _ = mimetypes.guess_type(str(file_path))\n            mime_type = guessed_mime_type or \"application/octet-stream\"\n\n        # Get extension\n        if file_path.suffix:\n            extension = file_path.suffix.lower()\n        else:\n            guessed_extension = mimetypes.guess_extension(mime_type)\n            extension = guessed_extension if guessed_extension else \".bin\"\n\n        return extension, mime_type\n\n    def _create_chunks(self, data: bytes) -&gt; list[bytes]:\n        \"\"\"Split data into chunks.\"\"\"\n        chunks = []\n        for i in range(0, len(data), self.chunk_size):\n            chunk = data[i : i + self.chunk_size]\n            chunks.append(chunk)\n        return chunks\n\n    async def _generate_image_names(self, count: int) -&gt; list[str]:\n        \"\"\"Generate random filenames for images.\"\"\"\n        names = []\n        for _ in range(count):\n            try:\n                # Try to get random name from API\n                response = await self._http_client.get(\"https://randomuser.me/api/?inc=email\")\n                response.raise_for_status()\n\n                data = response.json()\n                name_data = data[\"results\"][0][\"email\"].split(\"@\")[0]\n                filename = f\"{name_data}.png\"\n                # strip al non-alphanumeric characters\n\n                names.append(filename)\n\n            except Exception:\n                filename = f\"{uuid.uuid4().hex}.png\"\n                names.append(filename)\n\n        return names\n\n    def _encode_data_to_image(self, data: bytes, output_path: Path) -&gt; None:\n        \"\"\"Encode binary data into PNG image.\"\"\"\n        # Calculate required pixels\n        data_length = len(data)\n        total_pixels = self.IMAGE_WIDTH * self.IMAGE_HEIGHT\n        max_capacity = total_pixels * self.IMAGE_CHANNELS\n\n        if data_length &gt; max_capacity:\n            raise ValueError(f\"Data too large: {data_length} &gt; {max_capacity}\")\n\n        # Pad data to fill image if needed\n        padded_data = data + b\"\\x00\" * (max_capacity - data_length)\n\n        # Convert to numpy array and reshape\n        data_array = np.frombuffer(padded_data, dtype=np.uint8)\n        image_array = data_array.reshape((self.IMAGE_HEIGHT, self.IMAGE_WIDTH, self.IMAGE_CHANNELS))\n\n        # Create and save image\n        image = Image.fromarray(image_array, \"RGB\")\n        image.save(output_path, \"PNG\")\n\n    def _decode_data_from_image(self, image_path: Path) -&gt; bytes:\n        \"\"\"Decode binary data from PNG image.\"\"\"\n        # Load image\n        image = Image.open(image_path)\n        image_array = np.array(image)\n\n        # Flatten to bytes\n        data_bytes: bytes = image_array.flatten().tobytes()\n\n        return data_bytes\n\n    def _create_metadata(\n        self, file_metadata: dict[str, Any], chunk_infos: list[ChunkInfo], processed_data: bytes\n    ) -&gt; dict[str, Any]:\n        \"\"\"Create comprehensive metadata structure.\"\"\"\n        chunks_dict = {}\n        for chunk_info in chunk_infos:\n            chunks_dict[chunk_info.image_name] = {\n                \"chunk_id\": chunk_info.chunk_id,\n                \"data_bytes\": chunk_info.data_bytes,\n                \"chunk_hash\": chunk_info.chunk_hash,\n            }\n\n        metadata = {\n            \"version\": \"1.0.0\",\n            \"document\": {\n                \"filename\": file_metadata[\"filename\"],\n                \"extension\": file_metadata[\"extension\"],\n                \"mime_type\": file_metadata[\"mime_type\"],\n                \"original_size\": file_metadata[\"original_size\"],\n                \"compressed_size\": file_metadata[\"compressed_size\"],\n                \"hash\": file_metadata[\"hash\"],\n            },\n            \"chunks\": {\n                \"total\": len(chunk_infos),\n                \"chunk_size\": self.chunk_size,\n                \"total_processed_size\": len(processed_data),\n                \"images\": chunks_dict,\n            },\n            \"recovery\": {\n                \"error_correction_ratio\": self.ERROR_CORRECTION_RATIO,\n                \"chunk_overlap_bytes\": self.CHUNK_OVERLAP_BYTES,\n            },\n        }\n\n        # Add encryption info if key is used\n        if self.encryption_key:\n            metadata[\"encryption\"] = {\n                \"algorithm\": \"xor\",\n                \"encrypted\": True,\n            }\n        else:\n            metadata[\"encryption\"] = {\n                \"algorithm\": \"none\",\n                \"encrypted\": False,\n            }\n\n        return metadata\n\n    def _calculate_hash(self, data: bytes) -&gt; str:\n        \"\"\"Calculate SHA-256 hash.\"\"\"\n        return hashlib.sha256(data).hexdigest()\n\n    async def close(self) -&gt; None:\n        \"\"\"Clean up resources.\"\"\"\n        await self._http_client.aclose()\n\n    async def __aenter__(self) -&gt; \"Pixelator\":\n        \"\"\"Async context manager entry.\"\"\"\n        return self\n\n    async def __aexit__(self, exc_type: Any, exc_val: Any, exc_tb: Any) -&gt; None:\n        \"\"\"Async context manager exit.\"\"\"\n        await self.close()\n</code></pre>"},{"location":"reference/ciphergeist/#ciphergeist.Pixelator.__aenter__","title":"<code>__aenter__()</code>  <code>async</code>","text":"<p>Async context manager entry.</p> Source code in <code>src/ciphergeist/encoders/pixelator.py</code> <pre><code>async def __aenter__(self) -&gt; \"Pixelator\":\n    \"\"\"Async context manager entry.\"\"\"\n    return self\n</code></pre>"},{"location":"reference/ciphergeist/#ciphergeist.Pixelator.__aexit__","title":"<code>__aexit__(exc_type, exc_val, exc_tb)</code>  <code>async</code>","text":"<p>Async context manager exit.</p> Source code in <code>src/ciphergeist/encoders/pixelator.py</code> <pre><code>async def __aexit__(self, exc_type: Any, exc_val: Any, exc_tb: Any) -&gt; None:\n    \"\"\"Async context manager exit.\"\"\"\n    await self.close()\n</code></pre>"},{"location":"reference/ciphergeist/#ciphergeist.Pixelator.__init__","title":"<code>__init__(encryption_key=None)</code>","text":"<p>Initialize Pixelator.</p> <p>Parameters:</p> Name Type Description Default <code>encryption_key</code> <code>Optional[str]</code> <p>Optional XOR encryption key. If None, no encryption is used.</p> <code>None</code> Source code in <code>src/ciphergeist/encoders/pixelator.py</code> <pre><code>def __init__(self, encryption_key: Optional[str] = None) -&gt; None:\n    \"\"\"\n    Initialize Pixelator.\n\n    Args:\n        encryption_key: Optional XOR encryption key. If None, no encryption is used.\n    \"\"\"\n    self.encryption_key = encryption_key\n    self._magic = magic.Magic(mime=True)\n    self._http_client = httpx.AsyncClient(timeout=10.0)\n    self.image_capacity = self.IMAGE_WIDTH * self.IMAGE_HEIGHT * self.IMAGE_CHANNELS\n    self.chunk_size = self._calculate_optimal_chunk_size()\n</code></pre>"},{"location":"reference/ciphergeist/#ciphergeist.Pixelator.close","title":"<code>close()</code>  <code>async</code>","text":"<p>Clean up resources.</p> Source code in <code>src/ciphergeist/encoders/pixelator.py</code> <pre><code>async def close(self) -&gt; None:\n    \"\"\"Clean up resources.\"\"\"\n    await self._http_client.aclose()\n</code></pre>"},{"location":"reference/ciphergeist/#ciphergeist.Pixelator.decode_document","title":"<code>decode_document(metadata_image_path, output_path, images_dir=None)</code>  <code>async</code>","text":"<p>Decode document from images with optional decryption.</p> <p>Parameters:</p> Name Type Description Default <code>metadata_image_path</code> <code>Union[str, Path]</code> <p>Path to metadata image</p> required <code>output_path</code> <code>Union[str, Path]</code> <p>Path where to save decoded document</p> required <code>images_dir</code> <code>Optional[Union[str, Path]]</code> <p>Directory containing chunk images (default: same as metadata)</p> <code>None</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if successful, False otherwise</p> Source code in <code>src/ciphergeist/encoders/pixelator.py</code> <pre><code>async def decode_document(\n    self,\n    metadata_image_path: Union[str, Path],\n    output_path: Union[str, Path],\n    images_dir: Optional[Union[str, Path]] = None,\n) -&gt; bool:\n    \"\"\"\n    Decode document from images with optional decryption.\n\n    Args:\n        metadata_image_path: Path to metadata image\n        output_path: Path where to save decoded document\n        images_dir: Directory containing chunk images (default: same as metadata)\n\n    Returns:\n        True if successful, False otherwise\n    \"\"\"\n    metadata_image_path = Path(metadata_image_path)\n    output_path = Path(output_path)\n\n    images_dir = metadata_image_path.parent if images_dir is None else Path(images_dir)\n\n    try:\n        # Step 1: Decode metadata\n        metadata_data = self._decode_data_from_image(metadata_image_path)\n        metadata = json.loads(metadata_data.decode(\"utf-8\"))\n\n        # Step 2: Collect chunks\n        chunks_data = []\n        chunk_infos = metadata[\"chunks\"][\"images\"]\n\n        for image_name, chunk_info in chunk_infos.items():\n            chunk_path = images_dir / image_name\n            self._check_chunk_exists(chunk_path, image_name)\n\n            chunk_data = self._decode_data_from_image(chunk_path)\n            expected_size = chunk_info[\"data_bytes\"]\n            chunk_data = chunk_data[:expected_size]  # Trim to exact size\n\n            # Verify chunk integrity\n            self._verify_chunk_integrity(chunk_data, chunk_info[\"chunk_hash\"], image_name)\n\n            chunks_data.append((chunk_info[\"chunk_id\"], chunk_data))\n\n        # Step 3: Reassemble data\n        chunks_data.sort(key=lambda x: x[0])  # Sort by chunk_id\n        assembled_data = b\"\".join(chunk[1] for chunk in chunks_data)\n\n        # Step 4: Optionally decrypt data\n        if self.encryption_key and metadata.get(\"encryption\", {}).get(\"algorithm\") == \"xor\":\n            document_data = self._xor_encrypt_decrypt(assembled_data, self.encryption_key)\n        else:\n            document_data = assembled_data\n\n        # Step 5: Decompress and save\n        original_data = lzma.decompress(document_data)\n        output_path.write_bytes(original_data)\n\n    except Exception as e:\n        print(f\"Decoding failed: {e}\")\n        return False\n    else:\n        return True\n</code></pre>"},{"location":"reference/ciphergeist/#ciphergeist.Pixelator.encode_document","title":"<code>encode_document(file_path, output_dir='output')</code>  <code>async</code>","text":"<p>Encode document to images with optional encryption.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>Union[str, Path]</code> <p>Path to document to encode</p> required <code>output_dir</code> <code>Union[str, Path]</code> <p>Directory to save encoded images</p> <code>'output'</code> <p>Returns:</p> Type Description <code>EncodingResult</code> <p>EncodingResult with metadata and image information</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If input file doesn't exist</p> <code>ValueError</code> <p>If file cannot be processed</p> Source code in <code>src/ciphergeist/encoders/pixelator.py</code> <pre><code>async def encode_document(\n    self, file_path: Union[str, Path], output_dir: Union[str, Path] = \"output\"\n) -&gt; EncodingResult:\n    \"\"\"\n    Encode document to images with optional encryption.\n\n    Args:\n        file_path: Path to document to encode\n        output_dir: Directory to save encoded images\n\n    Returns:\n        EncodingResult with metadata and image information\n\n    Raises:\n        FileNotFoundError: If input file doesn't exist\n        ValueError: If file cannot be processed\n    \"\"\"\n    file_path = Path(file_path)\n    output_dir = Path(output_dir)\n    output_dir.mkdir(exist_ok=True)\n\n    # Step 1: Process document\n    document_data, file_metadata = self._process_document(file_path)\n\n    # Step 2: Optionally encrypt data\n    if self.encryption_key:\n        encrypted_data = self._xor_encrypt_decrypt(document_data, self.encryption_key)\n    else:\n        encrypted_data = document_data\n\n    # Step 3: Create chunks\n    chunks = self._create_chunks(encrypted_data)\n\n    # Step 4: Generate image names\n    chunk_names = await self._generate_image_names(len(chunks))\n\n    # Create metadata image name based on document name\n    document_name = file_path.stem  # Get filename without extension\n    metadata_image_name = f\"{document_name}_metadata.png\"\n\n    # Step 5: Create chunk images\n    chunk_infos = []\n    chunk_images = []\n\n    for i, (chunk_data, filename) in enumerate(zip(chunks, chunk_names)):\n        chunk_hash = self._calculate_hash(chunk_data)\n        image_path = output_dir / filename\n\n        self._encode_data_to_image(chunk_data, image_path)\n\n        chunk_infos.append(\n            ChunkInfo(chunk_id=i, image_name=filename, data_bytes=len(chunk_data), chunk_hash=chunk_hash)\n        )\n        chunk_images.append(filename)\n\n    # Step 6: Create metadata\n    metadata = self._create_metadata(file_metadata, chunk_infos, encrypted_data)\n\n    # Step 7: Create metadata image\n    metadata_path = output_dir / metadata_image_name\n    metadata_json = json.dumps(metadata, indent=2).encode(\"utf-8\")\n\n    self._encode_data_to_image(metadata_json, metadata_path)\n\n    return EncodingResult(\n        metadata_image=metadata_image_name,\n        chunk_images=chunk_images,\n        total_size=len(encrypted_data),\n        chunk_count=len(chunks),\n    )\n</code></pre>"},{"location":"reference/ciphergeist/#ciphergeist.fixed_xor","title":"<code>fixed_xor(a, b)</code>","text":"<p>Perform a fixed XOR operation on two byte strings.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>bytes</code> <p>The first byte string.</p> required <code>b</code> <code>bytes</code> <p>The second byte string.</p> required <p>Returns:</p> Name Type Description <code>bytes</code> <code>bytes</code> <p>The result of the XOR operation.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the input byte strings are of different lengths.</p> Source code in <code>src/ciphergeist/encrypters/xorxer.py</code> <pre><code>def fixed_xor(a: bytes, b: bytes) -&gt; bytes:\n    \"\"\"Perform a fixed XOR operation on two byte strings.\n\n    Args:\n        a (bytes): The first byte string.\n        b (bytes): The second byte string.\n\n    Returns:\n        bytes: The result of the XOR operation.\n\n    Raises:\n        ValueError: If the input byte strings are of different lengths.\n    \"\"\"\n    if len(a) != len(b):\n        raise ValueError(\"Input must be of the same length.\")\n    return bytes(x ^ y for x, y in zip(a, b))\n</code></pre>"},{"location":"reference/ciphergeist/#ciphergeist.guess_single_key_xor","title":"<code>guess_single_key_xor(ciphertext)</code>","text":"<p>Guess the single-byte XOR key for a given ciphertext.</p> <p>Iterates through all possible single-byte keys (0-255) and scores the resulting plaintext using letter frequency analysis.</p> <p>Parameters:</p> Name Type Description Default <code>ciphertext</code> <code>bytes</code> <p>The ciphertext to analyze.</p> required <p>Returns:</p> Name Type Description <code>Guess</code> <code>Guess</code> <p>The best guess containing the key, plaintext, and score.</p> Source code in <code>src/ciphergeist/encrypters/xorxer.py</code> <pre><code>def guess_single_key_xor(ciphertext: bytes) -&gt; Guess:\n    \"\"\"Guess the single-byte XOR key for a given ciphertext.\n\n    Iterates through all possible single-byte keys (0-255)\n    and scores the resulting plaintext using letter frequency analysis.\n\n    Args:\n        ciphertext (bytes): The ciphertext to analyze.\n\n    Returns:\n        Guess: The best guess containing the key, plaintext, and score.\n    \"\"\"\n    best_guess = Guess.empty()\n    for key in range(256):\n        current_guess = Guess(ciphertext, key)\n        best_guess = min(best_guess, current_guess)\n    return best_guess\n</code></pre>"},{"location":"reference/ciphergeist/#ciphergeist.quick_guess_single_byte_xor","title":"<code>quick_guess_single_byte_xor(ciphertext)</code>","text":"<p>Quickly guess a single-byte XOR key.</p> <p>Using letter frequency analysis. Asuming the most common byte in the ciphertext corresponds to the most common letter in English text (e.g., 'e', 't', 'a').</p> <p>Parameters:</p> Name Type Description Default <code>ciphertext</code> <code>bytes</code> <p>The ciphertext to analyze.</p> required <p>Returns:</p> Type Description <code>Guess</code> <p>list[tuple[float, int, bytes]]: A sorted list of tuples containing the score, key, and plaintext for each candidate key.</p> Source code in <code>src/ciphergeist/encrypters/xorxer.py</code> <pre><code>def quick_guess_single_byte_xor(ciphertext: bytes) -&gt; Guess:\n    \"\"\"Quickly guess a single-byte XOR key.\n\n    Using letter frequency analysis.\n    Asuming the most common byte in the ciphertext corresponds to\n    the most common letter in English text (e.g., 'e', 't', 'a').\n\n    Args:\n        ciphertext (bytes): The ciphertext to analyze.\n\n    Returns:\n        list[tuple[float, int, bytes]]: A sorted list of tuples containing the score,\n            key, and plaintext for each candidate key.\n    \"\"\"\n    frequencies = Counter(ciphertext)\n    most_common_byte = frequencies.most_common(1)[0][0]\n    common_chars = set(\" etaoinshrdlu\")\n    best_guess = Guess.empty()\n    for char in common_chars:\n        current_guess = Guess(ciphertext, most_common_byte ^ ord(char))\n        best_guess = min(best_guess, current_guess)\n    return best_guess\n</code></pre>"},{"location":"reference/ciphergeist/#ciphergeist.single_byte_xor","title":"<code>single_byte_xor(input_bytes, key)</code>","text":"<p>Perform a single-byte XOR operation on a byte string.</p> <p>Parameters:</p> Name Type Description Default <code>input_bytes</code> <code>bytes</code> <p>The byte string to be XORed.</p> required <code>key</code> <code>int</code> <p>The single-byte key to XOR with (0-255).</p> required <p>Returns:</p> Name Type Description <code>bytes</code> <code>bytes</code> <p>The result of the XOR operation.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the key is not an integer in the range 0-255.</p> Source code in <code>src/ciphergeist/encrypters/xorxer.py</code> <pre><code>def single_byte_xor(input_bytes: bytes, key: int) -&gt; bytes:\n    \"\"\"Perform a single-byte XOR operation on a byte string.\n\n    Args:\n        input_bytes (bytes): The byte string to be XORed.\n        key (int): The single-byte key to XOR with (0-255).\n\n    Returns:\n        bytes: The result of the XOR operation.\n\n    Raises:\n        ValueError: If the key is not an integer in the range 0-255.\n    \"\"\"\n    if not (0 &lt;= key &lt;= 255):\n        raise ValueError(\"Key must be int (0-255).\")\n    return bytes(b ^ key for b in input_bytes)\n</code></pre>"},{"location":"reference/ciphergeist/converter/","title":"converter","text":""},{"location":"reference/ciphergeist/converter/#ciphergeist.converter.convert_hex_to_base64","title":"<code>convert_hex_to_base64(hex_string)</code>","text":"<p>Convert a hexadecimal string to a Base64 encoded string.</p> <p>:param hex_string: A string representing a hexadecimal number. :return: A Base64 encoded string.</p> Source code in <code>src/ciphergeist/converter.py</code> <pre><code>def convert_hex_to_base64(hex_string: str) -&gt; str:\n    \"\"\"\n    Convert a hexadecimal string to a Base64 encoded string.\n\n    :param hex_string: A string representing a hexadecimal number.\n    :return: A Base64 encoded string.\n    \"\"\"\n    bytes_data = bytes.fromhex(hex_string)\n    base64_encoded = base64.b64encode(bytes_data)\n    return base64_encoded.decode(\"ascii\")\n</code></pre>"},{"location":"reference/ciphergeist/exceptions/","title":"exceptions","text":"<p>Custom exceptions for CipherGeist.</p>"},{"location":"reference/ciphergeist/exceptions/#ciphergeist.exceptions.CipherGeistError","title":"<code>CipherGeistError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Base exception for CipherGeist.</p> Source code in <code>src/ciphergeist/exceptions.py</code> <pre><code>class CipherGeistError(Exception):\n    \"\"\"Base exception for CipherGeist.\"\"\"\n\n    pass\n</code></pre>"},{"location":"reference/ciphergeist/exceptions/#ciphergeist.exceptions.CorruptedDataError","title":"<code>CorruptedDataError</code>","text":"<p>               Bases: <code>CipherGeistError</code></p> <p>Raised when data integrity checks fail.</p> Source code in <code>src/ciphergeist/exceptions.py</code> <pre><code>class CorruptedDataError(CipherGeistError):\n    \"\"\"Raised when data integrity checks fail.\"\"\"\n\n    pass\n</code></pre>"},{"location":"reference/ciphergeist/exceptions/#ciphergeist.exceptions.DecodingError","title":"<code>DecodingError</code>","text":"<p>               Bases: <code>CipherGeistError</code></p> <p>Raised when decoding operations fail.</p> Source code in <code>src/ciphergeist/exceptions.py</code> <pre><code>class DecodingError(CipherGeistError):\n    \"\"\"Raised when decoding operations fail.\"\"\"\n\n    pass\n</code></pre>"},{"location":"reference/ciphergeist/exceptions/#ciphergeist.exceptions.DecryptionError","title":"<code>DecryptionError</code>","text":"<p>               Bases: <code>CipherGeistError</code></p> <p>Raised when decryption operations fail.</p> Source code in <code>src/ciphergeist/exceptions.py</code> <pre><code>class DecryptionError(CipherGeistError):\n    \"\"\"Raised when decryption operations fail.\"\"\"\n\n    pass\n</code></pre>"},{"location":"reference/ciphergeist/exceptions/#ciphergeist.exceptions.EncodingError","title":"<code>EncodingError</code>","text":"<p>               Bases: <code>CipherGeistError</code></p> <p>Raised when encoding operations fail.</p> Source code in <code>src/ciphergeist/exceptions.py</code> <pre><code>class EncodingError(CipherGeistError):\n    \"\"\"Raised when encoding operations fail.\"\"\"\n\n    pass\n</code></pre>"},{"location":"reference/ciphergeist/exceptions/#ciphergeist.exceptions.EncryptionError","title":"<code>EncryptionError</code>","text":"<p>               Bases: <code>CipherGeistError</code></p> <p>Raised when encryption operations fail.</p> Source code in <code>src/ciphergeist/exceptions.py</code> <pre><code>class EncryptionError(CipherGeistError):\n    \"\"\"Raised when encryption operations fail.\"\"\"\n\n    pass\n</code></pre>"},{"location":"reference/ciphergeist/exceptions/#ciphergeist.exceptions.InvalidKeyError","title":"<code>InvalidKeyError</code>","text":"<p>               Bases: <code>CipherGeistError</code></p> <p>Raised when an invalid encryption key is provided.</p> Source code in <code>src/ciphergeist/exceptions.py</code> <pre><code>class InvalidKeyError(CipherGeistError):\n    \"\"\"Raised when an invalid encryption key is provided.\"\"\"\n\n    pass\n</code></pre>"},{"location":"reference/ciphergeist/analyzers/","title":"Index","text":"<p>Cryptanalysis and text analysis tools.</p> <p>This module contains various analyzers for determining the likelihood that decrypted text is meaningful in various languages or contexts.</p>"},{"location":"reference/ciphergeist/analyzers/#ciphergeist.analyzers.EnglishAnalyzer","title":"<code>EnglishAnalyzer</code>","text":"<p>Analyzer for determining if text is likely to be English.</p> Source code in <code>src/ciphergeist/analyzers/text_analyzer.py</code> <pre><code>class EnglishAnalyzer:\n    \"\"\"Analyzer for determining if text is likely to be English.\"\"\"\n\n    # Expected ratios for English text\n    EXPECTED_SPACE_RATIO = 0.13\n    EXPECTED_PRINTABLE_RATIO = 0.95\n\n    # Calibrated thresholds (based on actual testing with various English texts)\n    ENGLISH_FREQUENCY_MEAN = 0.25  # Lower mean based on real English text\n    ENGLISH_FREQUENCY_STD = 0.15  # Adjusted standard deviation\n\n    def __init__(self, normalize: bool = True) -&gt; None:\n        \"\"\"Initialize with optional custom frequency scoring function and normalization.\n\n        Args:\n            normalize: Whether to normalize text before analysis (lowercase, reduce whitespace)\n        \"\"\"\n        from ciphergeist.encrypters.xorxer import score_text\n\n        self.frequency_scorer = score_text\n        self.normalize = normalize\n\n    def normalize_text(self, text: bytes) -&gt; bytes:\n        \"\"\"Normalize text for better analysis.\n\n        - Converts to lowercase (critical since frequency scorer only counts lowercase)\n        - Reduces multiple whitespace to single spaces\n        - Strips leading/trailing whitespace\n        \"\"\"\n        if not self.normalize:\n            return text\n\n        try:\n            # Decode to string for easier processing\n            text_str = text.decode(\"utf-8\", errors=\"ignore\")\n\n            # Convert to lowercase (critical for frequency analysis)\n            text_str = text_str.lower()\n\n            # Reduce multiple whitespace to single spaces\n            import re\n\n            text_str = re.sub(r\"\\s+\", \" \", text_str)\n\n            # Strip leading/trailing whitespace\n            text_str = text_str.strip()\n\n            return text_str.encode(\"utf-8\")\n        except Exception:\n            return text\n\n    def analyze(self, text: bytes) -&gt; TextAnalysisResult:\n        \"\"\"Perform comprehensive analysis of text with optional normalization.\"\"\"\n        if not text:\n            return TextAnalysisResult(\n                frequency_score=float(\"inf\"),\n                printable_ratio=0.0,\n                space_ratio=0.0,\n                english_probability=0.0,\n                confidence_level=\"No text\",\n            )\n\n        # Normalize text if enabled (default)\n        if self.normalize:\n            text = self.normalize_text(text)\n\n        # Calculate individual metrics\n        frequency_score = self.frequency_scorer(text)\n        printable_ratio = self._calculate_printable_ratio(text)\n        space_ratio = self._calculate_space_ratio(text)\n\n        # Calculate overall English probability\n        english_probability = self._calculate_english_probability(\n            frequency_score, printable_ratio, space_ratio, len(text)\n        )\n\n        confidence_level = self._get_confidence_level(english_probability)\n\n        return TextAnalysisResult(\n            frequency_score=frequency_score,\n            printable_ratio=printable_ratio,\n            space_ratio=space_ratio,\n            english_probability=english_probability,\n            confidence_level=confidence_level,\n        )\n\n    def _calculate_printable_ratio(self, text: bytes) -&gt; float:\n        \"\"\"Calculate ratio of printable ASCII characters.\"\"\"\n        printable_count = sum(1 for b in text if 32 &lt;= b &lt;= 126)\n        return printable_count / len(text)\n\n    def _calculate_space_ratio(self, text: bytes) -&gt; float:\n        \"\"\"Calculate ratio of space characters.\"\"\"\n        space_count = text.count(b\" \")\n        return space_count / len(text)\n\n    def _calculate_english_probability(\n        self, frequency_score: float, printable_ratio: float, space_ratio: float, text_length: int\n    ) -&gt; float:\n        \"\"\"Calculate probability that text is English using multiple factors.\"\"\"\n\n        # Start with frequency-based probability (more lenient scoring)\n        freq_z_score = (frequency_score - self.ENGLISH_FREQUENCY_MEAN) / self.ENGLISH_FREQUENCY_STD\n        freq_prob = max(0.01, min(0.99, 1 / (1 + abs(freq_z_score) * 0.5)))  # Less harsh penalty\n\n        # Adjust based on printable character ratio (more lenient)\n        printable_penalty = max(0.3, printable_ratio / self.EXPECTED_PRINTABLE_RATIO)\n\n        # Adjust based on space ratio (more tolerant of variation)\n        space_diff = abs(space_ratio - self.EXPECTED_SPACE_RATIO)\n        space_penalty = max(0.7, 1 - (space_diff * 2))  # Less harsh space penalty\n\n        # Combine all factors (without word boost for better short text handling)\n        probability = freq_prob * printable_penalty * space_penalty\n\n        return max(0.01, min(0.99, probability))\n\n    def _get_confidence_level(self, probability: float) -&gt; str:\n        \"\"\"Convert probability to human-readable confidence level.\"\"\"\n        if probability &gt;= 0.8:\n            return \"Very High\"\n        elif probability &gt;= 0.6:\n            return \"High\"\n        elif probability &gt;= 0.4:\n            return \"Medium\"\n        elif probability &gt;= 0.2:\n            return \"Low\"\n        else:\n            return \"Very Low\"\n</code></pre>"},{"location":"reference/ciphergeist/analyzers/#ciphergeist.analyzers.EnglishAnalyzer.__init__","title":"<code>__init__(normalize=True)</code>","text":"<p>Initialize with optional custom frequency scoring function and normalization.</p> <p>Parameters:</p> Name Type Description Default <code>normalize</code> <code>bool</code> <p>Whether to normalize text before analysis (lowercase, reduce whitespace)</p> <code>True</code> Source code in <code>src/ciphergeist/analyzers/text_analyzer.py</code> <pre><code>def __init__(self, normalize: bool = True) -&gt; None:\n    \"\"\"Initialize with optional custom frequency scoring function and normalization.\n\n    Args:\n        normalize: Whether to normalize text before analysis (lowercase, reduce whitespace)\n    \"\"\"\n    from ciphergeist.encrypters.xorxer import score_text\n\n    self.frequency_scorer = score_text\n    self.normalize = normalize\n</code></pre>"},{"location":"reference/ciphergeist/analyzers/#ciphergeist.analyzers.EnglishAnalyzer.analyze","title":"<code>analyze(text)</code>","text":"<p>Perform comprehensive analysis of text with optional normalization.</p> Source code in <code>src/ciphergeist/analyzers/text_analyzer.py</code> <pre><code>def analyze(self, text: bytes) -&gt; TextAnalysisResult:\n    \"\"\"Perform comprehensive analysis of text with optional normalization.\"\"\"\n    if not text:\n        return TextAnalysisResult(\n            frequency_score=float(\"inf\"),\n            printable_ratio=0.0,\n            space_ratio=0.0,\n            english_probability=0.0,\n            confidence_level=\"No text\",\n        )\n\n    # Normalize text if enabled (default)\n    if self.normalize:\n        text = self.normalize_text(text)\n\n    # Calculate individual metrics\n    frequency_score = self.frequency_scorer(text)\n    printable_ratio = self._calculate_printable_ratio(text)\n    space_ratio = self._calculate_space_ratio(text)\n\n    # Calculate overall English probability\n    english_probability = self._calculate_english_probability(\n        frequency_score, printable_ratio, space_ratio, len(text)\n    )\n\n    confidence_level = self._get_confidence_level(english_probability)\n\n    return TextAnalysisResult(\n        frequency_score=frequency_score,\n        printable_ratio=printable_ratio,\n        space_ratio=space_ratio,\n        english_probability=english_probability,\n        confidence_level=confidence_level,\n    )\n</code></pre>"},{"location":"reference/ciphergeist/analyzers/#ciphergeist.analyzers.EnglishAnalyzer.normalize_text","title":"<code>normalize_text(text)</code>","text":"<p>Normalize text for better analysis.</p> <ul> <li>Converts to lowercase (critical since frequency scorer only counts lowercase)</li> <li>Reduces multiple whitespace to single spaces</li> <li>Strips leading/trailing whitespace</li> </ul> Source code in <code>src/ciphergeist/analyzers/text_analyzer.py</code> <pre><code>def normalize_text(self, text: bytes) -&gt; bytes:\n    \"\"\"Normalize text for better analysis.\n\n    - Converts to lowercase (critical since frequency scorer only counts lowercase)\n    - Reduces multiple whitespace to single spaces\n    - Strips leading/trailing whitespace\n    \"\"\"\n    if not self.normalize:\n        return text\n\n    try:\n        # Decode to string for easier processing\n        text_str = text.decode(\"utf-8\", errors=\"ignore\")\n\n        # Convert to lowercase (critical for frequency analysis)\n        text_str = text_str.lower()\n\n        # Reduce multiple whitespace to single spaces\n        import re\n\n        text_str = re.sub(r\"\\s+\", \" \", text_str)\n\n        # Strip leading/trailing whitespace\n        text_str = text_str.strip()\n\n        return text_str.encode(\"utf-8\")\n    except Exception:\n        return text\n</code></pre>"},{"location":"reference/ciphergeist/analyzers/#ciphergeist.analyzers.TextAnalysisResult","title":"<code>TextAnalysisResult</code>  <code>dataclass</code>","text":"<p>Result of text analysis with multiple confidence metrics.</p> Source code in <code>src/ciphergeist/analyzers/text_analyzer.py</code> <pre><code>@dataclass\nclass TextAnalysisResult:\n    \"\"\"Result of text analysis with multiple confidence metrics.\"\"\"\n\n    frequency_score: float\n    printable_ratio: float\n    space_ratio: float\n    english_probability: float\n    confidence_level: str\n\n    def __str__(self) -&gt; str:\n        return f\"English probability: {self.english_probability:.1%} ({self.confidence_level})\"\n</code></pre>"},{"location":"reference/ciphergeist/analyzers/#ciphergeist.analyzers.analyze_english_probability","title":"<code>analyze_english_probability(text)</code>","text":"<p>Convenience function for quick English analysis.</p> Source code in <code>src/ciphergeist/analyzers/text_analyzer.py</code> <pre><code>def analyze_english_probability(text: bytes) -&gt; TextAnalysisResult:\n    \"\"\"Convenience function for quick English analysis.\"\"\"\n    analyzer = EnglishAnalyzer()\n    return analyzer.analyze(text)\n</code></pre>"},{"location":"reference/ciphergeist/analyzers/example_usage/","title":"example_usage","text":"<p>Example of using the text analyzer with XOR decryption.</p> <p>This shows how to get absolute confidence (English probability) rather than just relative confidence (best among options).</p>"},{"location":"reference/ciphergeist/analyzers/example_usage/#ciphergeist.analyzers.example_usage.enhanced_xor_analysis","title":"<code>enhanced_xor_analysis(ciphertext)</code>","text":"<p>Analyze XOR decryption with both relative and absolute confidence.</p> Source code in <code>src/ciphergeist/analyzers/example_usage.py</code> <pre><code>def enhanced_xor_analysis(ciphertext: bytes) -&gt; tuple:\n    \"\"\"Analyze XOR decryption with both relative and absolute confidence.\"\"\"\n\n    # Get the best guess using existing method\n    best_guess = guess_single_key_xor(ciphertext)\n\n    # Analyze the English probability of the result\n    analysis = analyze_english_probability(best_guess.plaintext)\n\n    print(\"=== XOR Analysis Results ===\")\n    print(f\"Best key: {best_guess.key}\")\n    print(f\"Frequency score: {best_guess.score:.4f}\")\n    print(f\"Plaintext: {best_guess.plaintext.decode(errors='replace')}\")\n    print()\n    print(\"=== English Analysis ===\")\n    print(f\"English probability: {analysis.english_probability:.1%}\")\n    print(f\"Confidence level: {analysis.confidence_level}\")\n    print(f\"Printable ratio: {analysis.printable_ratio:.1%}\")\n    print(f\"Space ratio: {analysis.space_ratio:.1%}\")\n\n    return best_guess, analysis\n</code></pre>"},{"location":"reference/ciphergeist/analyzers/example_usage/#ciphergeist.analyzers.example_usage.test_analyzer_on_books","title":"<code>test_analyzer_on_books()</code>","text":"<p>Test the English analyzer on real English text from books.</p> Source code in <code>src/ciphergeist/analyzers/example_usage.py</code> <pre><code>def test_analyzer_on_books() -&gt; None:\n    \"\"\"Test the English analyzer on real English text from books.\"\"\"\n    import os\n\n    books_dir = os.path.join(os.path.dirname(__file__), \"..\", \"books\")\n    available_books = [\"alice_in_wonderland.txt\", \"dracula.txt\", \"frankenstein.txt\", \"sherlock_holmes.txt\"]\n\n    print(\"=== Testing English Analyzer on Real Books ===\")\n\n    for book_name in available_books:\n        book_path = os.path.join(books_dir, book_name)\n        try:\n            with open(book_path, \"rb\") as f:\n                # Read first 1000 bytes as a sample\n                text_sample = f.read(1000)\n\n            analysis = analyze_english_probability(text_sample)\n\n            print(f\"\\n{book_name}:\")\n            print(f\"  English probability: {analysis.english_probability:.1%}\")\n            print(f\"  Confidence level: {analysis.confidence_level}\")\n            print(f\"  Frequency score: {analysis.frequency_score:.4f}\")\n            print(f\"  Printable ratio: {analysis.printable_ratio:.1%}\")\n            print(f\"  Space ratio: {analysis.space_ratio:.1%}\")\n            print(f\"  Sample text: {text_sample[:100].decode(errors='replace')}...\")\n\n        except FileNotFoundError:\n            print(f\"  {book_name}: File not found\")\n        except Exception as e:\n            print(f\"  {book_name}: Error - {e}\")\n</code></pre>"},{"location":"reference/ciphergeist/analyzers/text_analyzer/","title":"text_analyzer","text":"<p>Text analysis for determining if decrypted content is meaningful English.</p> <p>This module provides sophisticated analysis beyond simple letter frequency, including statistical confidence measures, multiple scoring metrics, and automatic text normalization for better accuracy.</p>"},{"location":"reference/ciphergeist/analyzers/text_analyzer/#ciphergeist.analyzers.text_analyzer.EnglishAnalyzer","title":"<code>EnglishAnalyzer</code>","text":"<p>Analyzer for determining if text is likely to be English.</p> Source code in <code>src/ciphergeist/analyzers/text_analyzer.py</code> <pre><code>class EnglishAnalyzer:\n    \"\"\"Analyzer for determining if text is likely to be English.\"\"\"\n\n    # Expected ratios for English text\n    EXPECTED_SPACE_RATIO = 0.13\n    EXPECTED_PRINTABLE_RATIO = 0.95\n\n    # Calibrated thresholds (based on actual testing with various English texts)\n    ENGLISH_FREQUENCY_MEAN = 0.25  # Lower mean based on real English text\n    ENGLISH_FREQUENCY_STD = 0.15  # Adjusted standard deviation\n\n    def __init__(self, normalize: bool = True) -&gt; None:\n        \"\"\"Initialize with optional custom frequency scoring function and normalization.\n\n        Args:\n            normalize: Whether to normalize text before analysis (lowercase, reduce whitespace)\n        \"\"\"\n        from ciphergeist.encrypters.xorxer import score_text\n\n        self.frequency_scorer = score_text\n        self.normalize = normalize\n\n    def normalize_text(self, text: bytes) -&gt; bytes:\n        \"\"\"Normalize text for better analysis.\n\n        - Converts to lowercase (critical since frequency scorer only counts lowercase)\n        - Reduces multiple whitespace to single spaces\n        - Strips leading/trailing whitespace\n        \"\"\"\n        if not self.normalize:\n            return text\n\n        try:\n            # Decode to string for easier processing\n            text_str = text.decode(\"utf-8\", errors=\"ignore\")\n\n            # Convert to lowercase (critical for frequency analysis)\n            text_str = text_str.lower()\n\n            # Reduce multiple whitespace to single spaces\n            import re\n\n            text_str = re.sub(r\"\\s+\", \" \", text_str)\n\n            # Strip leading/trailing whitespace\n            text_str = text_str.strip()\n\n            return text_str.encode(\"utf-8\")\n        except Exception:\n            return text\n\n    def analyze(self, text: bytes) -&gt; TextAnalysisResult:\n        \"\"\"Perform comprehensive analysis of text with optional normalization.\"\"\"\n        if not text:\n            return TextAnalysisResult(\n                frequency_score=float(\"inf\"),\n                printable_ratio=0.0,\n                space_ratio=0.0,\n                english_probability=0.0,\n                confidence_level=\"No text\",\n            )\n\n        # Normalize text if enabled (default)\n        if self.normalize:\n            text = self.normalize_text(text)\n\n        # Calculate individual metrics\n        frequency_score = self.frequency_scorer(text)\n        printable_ratio = self._calculate_printable_ratio(text)\n        space_ratio = self._calculate_space_ratio(text)\n\n        # Calculate overall English probability\n        english_probability = self._calculate_english_probability(\n            frequency_score, printable_ratio, space_ratio, len(text)\n        )\n\n        confidence_level = self._get_confidence_level(english_probability)\n\n        return TextAnalysisResult(\n            frequency_score=frequency_score,\n            printable_ratio=printable_ratio,\n            space_ratio=space_ratio,\n            english_probability=english_probability,\n            confidence_level=confidence_level,\n        )\n\n    def _calculate_printable_ratio(self, text: bytes) -&gt; float:\n        \"\"\"Calculate ratio of printable ASCII characters.\"\"\"\n        printable_count = sum(1 for b in text if 32 &lt;= b &lt;= 126)\n        return printable_count / len(text)\n\n    def _calculate_space_ratio(self, text: bytes) -&gt; float:\n        \"\"\"Calculate ratio of space characters.\"\"\"\n        space_count = text.count(b\" \")\n        return space_count / len(text)\n\n    def _calculate_english_probability(\n        self, frequency_score: float, printable_ratio: float, space_ratio: float, text_length: int\n    ) -&gt; float:\n        \"\"\"Calculate probability that text is English using multiple factors.\"\"\"\n\n        # Start with frequency-based probability (more lenient scoring)\n        freq_z_score = (frequency_score - self.ENGLISH_FREQUENCY_MEAN) / self.ENGLISH_FREQUENCY_STD\n        freq_prob = max(0.01, min(0.99, 1 / (1 + abs(freq_z_score) * 0.5)))  # Less harsh penalty\n\n        # Adjust based on printable character ratio (more lenient)\n        printable_penalty = max(0.3, printable_ratio / self.EXPECTED_PRINTABLE_RATIO)\n\n        # Adjust based on space ratio (more tolerant of variation)\n        space_diff = abs(space_ratio - self.EXPECTED_SPACE_RATIO)\n        space_penalty = max(0.7, 1 - (space_diff * 2))  # Less harsh space penalty\n\n        # Combine all factors (without word boost for better short text handling)\n        probability = freq_prob * printable_penalty * space_penalty\n\n        return max(0.01, min(0.99, probability))\n\n    def _get_confidence_level(self, probability: float) -&gt; str:\n        \"\"\"Convert probability to human-readable confidence level.\"\"\"\n        if probability &gt;= 0.8:\n            return \"Very High\"\n        elif probability &gt;= 0.6:\n            return \"High\"\n        elif probability &gt;= 0.4:\n            return \"Medium\"\n        elif probability &gt;= 0.2:\n            return \"Low\"\n        else:\n            return \"Very Low\"\n</code></pre>"},{"location":"reference/ciphergeist/analyzers/text_analyzer/#ciphergeist.analyzers.text_analyzer.EnglishAnalyzer.__init__","title":"<code>__init__(normalize=True)</code>","text":"<p>Initialize with optional custom frequency scoring function and normalization.</p> <p>Parameters:</p> Name Type Description Default <code>normalize</code> <code>bool</code> <p>Whether to normalize text before analysis (lowercase, reduce whitespace)</p> <code>True</code> Source code in <code>src/ciphergeist/analyzers/text_analyzer.py</code> <pre><code>def __init__(self, normalize: bool = True) -&gt; None:\n    \"\"\"Initialize with optional custom frequency scoring function and normalization.\n\n    Args:\n        normalize: Whether to normalize text before analysis (lowercase, reduce whitespace)\n    \"\"\"\n    from ciphergeist.encrypters.xorxer import score_text\n\n    self.frequency_scorer = score_text\n    self.normalize = normalize\n</code></pre>"},{"location":"reference/ciphergeist/analyzers/text_analyzer/#ciphergeist.analyzers.text_analyzer.EnglishAnalyzer.analyze","title":"<code>analyze(text)</code>","text":"<p>Perform comprehensive analysis of text with optional normalization.</p> Source code in <code>src/ciphergeist/analyzers/text_analyzer.py</code> <pre><code>def analyze(self, text: bytes) -&gt; TextAnalysisResult:\n    \"\"\"Perform comprehensive analysis of text with optional normalization.\"\"\"\n    if not text:\n        return TextAnalysisResult(\n            frequency_score=float(\"inf\"),\n            printable_ratio=0.0,\n            space_ratio=0.0,\n            english_probability=0.0,\n            confidence_level=\"No text\",\n        )\n\n    # Normalize text if enabled (default)\n    if self.normalize:\n        text = self.normalize_text(text)\n\n    # Calculate individual metrics\n    frequency_score = self.frequency_scorer(text)\n    printable_ratio = self._calculate_printable_ratio(text)\n    space_ratio = self._calculate_space_ratio(text)\n\n    # Calculate overall English probability\n    english_probability = self._calculate_english_probability(\n        frequency_score, printable_ratio, space_ratio, len(text)\n    )\n\n    confidence_level = self._get_confidence_level(english_probability)\n\n    return TextAnalysisResult(\n        frequency_score=frequency_score,\n        printable_ratio=printable_ratio,\n        space_ratio=space_ratio,\n        english_probability=english_probability,\n        confidence_level=confidence_level,\n    )\n</code></pre>"},{"location":"reference/ciphergeist/analyzers/text_analyzer/#ciphergeist.analyzers.text_analyzer.EnglishAnalyzer.normalize_text","title":"<code>normalize_text(text)</code>","text":"<p>Normalize text for better analysis.</p> <ul> <li>Converts to lowercase (critical since frequency scorer only counts lowercase)</li> <li>Reduces multiple whitespace to single spaces</li> <li>Strips leading/trailing whitespace</li> </ul> Source code in <code>src/ciphergeist/analyzers/text_analyzer.py</code> <pre><code>def normalize_text(self, text: bytes) -&gt; bytes:\n    \"\"\"Normalize text for better analysis.\n\n    - Converts to lowercase (critical since frequency scorer only counts lowercase)\n    - Reduces multiple whitespace to single spaces\n    - Strips leading/trailing whitespace\n    \"\"\"\n    if not self.normalize:\n        return text\n\n    try:\n        # Decode to string for easier processing\n        text_str = text.decode(\"utf-8\", errors=\"ignore\")\n\n        # Convert to lowercase (critical for frequency analysis)\n        text_str = text_str.lower()\n\n        # Reduce multiple whitespace to single spaces\n        import re\n\n        text_str = re.sub(r\"\\s+\", \" \", text_str)\n\n        # Strip leading/trailing whitespace\n        text_str = text_str.strip()\n\n        return text_str.encode(\"utf-8\")\n    except Exception:\n        return text\n</code></pre>"},{"location":"reference/ciphergeist/analyzers/text_analyzer/#ciphergeist.analyzers.text_analyzer.TextAnalysisResult","title":"<code>TextAnalysisResult</code>  <code>dataclass</code>","text":"<p>Result of text analysis with multiple confidence metrics.</p> Source code in <code>src/ciphergeist/analyzers/text_analyzer.py</code> <pre><code>@dataclass\nclass TextAnalysisResult:\n    \"\"\"Result of text analysis with multiple confidence metrics.\"\"\"\n\n    frequency_score: float\n    printable_ratio: float\n    space_ratio: float\n    english_probability: float\n    confidence_level: str\n\n    def __str__(self) -&gt; str:\n        return f\"English probability: {self.english_probability:.1%} ({self.confidence_level})\"\n</code></pre>"},{"location":"reference/ciphergeist/analyzers/text_analyzer/#ciphergeist.analyzers.text_analyzer.analyze_english_probability","title":"<code>analyze_english_probability(text)</code>","text":"<p>Convenience function for quick English analysis.</p> Source code in <code>src/ciphergeist/analyzers/text_analyzer.py</code> <pre><code>def analyze_english_probability(text: bytes) -&gt; TextAnalysisResult:\n    \"\"\"Convenience function for quick English analysis.\"\"\"\n    analyzer = EnglishAnalyzer()\n    return analyzer.analyze(text)\n</code></pre>"},{"location":"reference/ciphergeist/analyzers/text_analyzer/#ciphergeist.analyzers.text_analyzer.compare_candidates","title":"<code>compare_candidates(candidates)</code>","text":"<p>Analyze multiple candidate texts and return sorted by English probability.</p> Source code in <code>src/ciphergeist/analyzers/text_analyzer.py</code> <pre><code>def compare_candidates(candidates: list[bytes]) -&gt; list[TextAnalysisResult]:\n    \"\"\"Analyze multiple candidate texts and return sorted by English probability.\"\"\"\n    analyzer = EnglishAnalyzer()\n    results = [analyzer.analyze(candidate) for candidate in candidates]\n    return sorted(results, key=lambda r: r.english_probability, reverse=True)\n</code></pre>"},{"location":"reference/ciphergeist/decrypters/","title":"Index","text":"<p>RSA and other decryption tools for ciphergeist.</p>"},{"location":"reference/ciphergeist/decrypters/rsa_decrypter/","title":"rsa_decrypter","text":"<p>RSA decryption tools with various attack methods.</p>"},{"location":"reference/ciphergeist/decrypters/rsa_decrypter/#ciphergeist.decrypters.rsa_decrypter.RSADecrypter","title":"<code>RSADecrypter</code>","text":"<p>RSA decryption toolkit with multiple attack vectors.</p> <p>EDUCATIONAL NOTE - ATTACK METHOD EFFECTIVENESS:</p> <p>This toolkit implements multiple RSA attack methods for educational purposes. In practice, the effectiveness order is:</p> <ol> <li> <p>FactorDB lookup - Covers ~95% of solvable CTF cases instantly by querying    a database of millions of pre-computed factorizations</p> </li> <li> <p>Small exponent attack - Targets a different vulnerability class (small e    with small messages), independent of factorization difficulty</p> </li> </ol> <p>3-5. Local factorization methods (small primes, Pollard's rho, Fermat) -      Mostly educational after FactorDB fails, since if FactorDB doesn't have      the factorization, these methods are very unlikely to succeed. FactorDB      contains all \"easy\" cases these methods would find. Mainly useful for      offline scenarios, network issues, or out of curiosity.</p> <p>The local factorization methods are included for completeness, education, and understanding of classical cryptanalysis techniques.</p> Source code in <code>src/ciphergeist/decrypters/rsa_decrypter.py</code> <pre><code>class RSADecrypter:\n    \"\"\"RSA decryption toolkit with multiple attack vectors.\n\n    EDUCATIONAL NOTE - ATTACK METHOD EFFECTIVENESS:\n\n    This toolkit implements multiple RSA attack methods for educational purposes.\n    In practice, the effectiveness order is:\n\n    1. FactorDB lookup - Covers ~95% of solvable CTF cases instantly by querying\n       a database of millions of pre-computed factorizations\n\n    2. Small exponent attack - Targets a different vulnerability class (small e\n       with small messages), independent of factorization difficulty\n\n    3-5. Local factorization methods (small primes, Pollard's rho, Fermat) -\n         Mostly educational after FactorDB fails, since if FactorDB doesn't have\n         the factorization, these methods are very unlikely to succeed. FactorDB\n         contains all \"easy\" cases these methods would find. Mainly useful for\n         offline scenarios, network issues, or out of curiosity.\n\n    The local factorization methods are included for completeness, education,\n    and understanding of classical cryptanalysis techniques.\n    \"\"\"\n\n    def __init__(self, n: int, e: int, ciphertext: int, verbose: bool = False):\n        \"\"\"Initialize RSA decrypter with public parameters and ciphertext.\n\n        Args:\n            n: Public modulus\n            e: Public exponent\n            ciphertext: Encrypted message\n            verbose: Whether to print detailed information (default False)\n        \"\"\"\n        self.n = n\n        self.e = e\n        self.ciphertext = ciphertext\n        self.p: Optional[int] = None\n        self.q: Optional[int] = None\n        self.d: Optional[int] = None\n        self.verbose = verbose\n\n    def _extract_rsa_factors(self, data: dict) -&gt; Optional[tuple[int, int]]:\n        \"\"\"Extract RSA factors from FactorDB response data.\n\n        Args:\n            data: JSON response from FactorDB API\n\n        Returns:\n            Tuple of (p, q) if valid RSA factors found, None otherwise\n        \"\"\"\n        factors = data.get(\"factors\", [])\n\n        # Look for exactly 2 prime factors (typical RSA)\n        prime_factors = []\n        for factor_info in factors:\n            factor_str = factor_info[0]\n            exponent = factor_info[1]\n\n            if exponent == 1:  # Only consider factors with exponent 1\n                try:\n                    factor_int = int(factor_str)\n                    prime_factors.append(factor_int)\n                except ValueError:\n                    continue\n\n        if len(prime_factors) == 2:\n            p, q = prime_factors[0], prime_factors[1]\n            if p * q == self.n:\n                if self.verbose:\n                    print(f\"FactorDB found factors: p = {p}, q = {q}\")\n                else:\n                    print(f\"FactorDB found factors: p = {min(p, q)}, q = (use verbose mode)\")\n                self.p, self.q = p, q\n                return p, q\n\n        print(\"FactorDB found factorization but not suitable for RSA\")\n        return None\n\n    def factordb_lookup(self) -&gt; Optional[tuple[int, int]]:\n        \"\"\"Query FactorDB.com for known factorizations.\n\n        Returns:\n            Tuple of (p, q) if factorization found, None otherwise\n        \"\"\"\n        if not HTTPX_AVAILABLE:\n            if self.verbose:\n                print(\"FactorDB lookup skipped: httpx not available\")\n            return None\n\n        print(\"Checking FactorDB.com for known factorization...\")\n\n        try:\n            url = f\"https://factordb.com/api?query={self.n}\"\n            response = httpx.get(url, timeout=10.0)\n\n            if response.status_code != 200:\n                print(\"FactorDB lookup failed: HTTP error\")\n                return None\n\n            data = response.json()\n\n            # Check if the number is factored\n            if data.get(\"status\") == \"FF\":  # Fully Factored\n                return self._extract_rsa_factors(data)\n            else:\n                print(\"FactorDB: Number not fully factored\")\n                return None\n\n        except Exception as e:\n            if self.verbose:\n                print(f\"FactorDB lookup failed: {e}\")\n            else:\n                print(\"FactorDB lookup failed\")\n            return None\n\n    def factor_small_primes(self, max_prime: int = 10000) -&gt; Optional[tuple[int, int]]:\n        \"\"\"Attempt to factor n by testing small prime factors.\n\n        Args:\n            max_prime: Maximum prime to test (default 10000)\n\n        Returns:\n            Tuple of (p, q) if factorization found, None otherwise\n        \"\"\"\n        print(f\"Attempting to factor n with small primes up to {max_prime}...\")\n\n        # Test small prime factors\n        # Use a more efficient approach for very large numbers\n        sqrt_limit = min(max_prime, 100000)  # Cap the search to avoid overflow\n\n        for i in range(2, sqrt_limit):\n            if self.n % i == 0:\n                p = i\n                q = self.n // i\n                if self.verbose:\n                    print(f\"Found factors: p = {p}, q = {q}\")\n                else:\n                    print(f\"Found factors: p = {p}, q = (use verbose mode)\")\n                self.p, self.q = p, q\n                return p, q\n\n        print(\"No small prime factors found\")\n        return None\n\n    def pollards_rho(self, max_iterations: int = 100000) -&gt; Optional[tuple[int, int]]:\n        \"\"\"Pollard's rho algorithm for factorization.\n\n        Args:\n            max_iterations: Maximum iterations to attempt\n\n        Returns:\n            Tuple of (p, q) if factorization found, None otherwise\n        \"\"\"\n        print(\"Attempting Pollard's rho factorization...\")\n\n        def f(x: int) -&gt; int:\n            return (x * x + 1) % self.n\n\n        x = 2\n        y = 2\n\n        for _ in range(max_iterations):\n            x = f(x)\n            y = f(f(y))\n\n            gcd_val = GCD(abs(x - y), self.n)\n\n            if 1 &lt; gcd_val &lt; self.n:\n                p = gcd_val\n                q = self.n // p\n                if self.verbose:\n                    print(f\"Pollard's rho found factors: p = {p}, q = {q}\")\n                else:\n                    print(f\"Pollard's rho found factors: p = {p}, q = (use verbose mode)\")\n                self.p, self.q = p, q\n                return p, q\n\n        print(\"Pollard's rho failed to find factors\")\n        return None\n\n    def fermat_factorization(self, max_iterations: int = 100000) -&gt; Optional[tuple[int, int]]:\n        \"\"\"Fermat's factorization method (works well when p and q are close).\n\n        Args:\n            max_iterations: Maximum iterations to attempt\n\n        Returns:\n            Tuple of (p, q) if factorization found, None otherwise\n        \"\"\"\n        print(\"Attempting Fermat factorization...\")\n\n        a = math.isqrt(self.n) + 1\n\n        for _ in range(max_iterations):\n            b_squared = a * a - self.n\n            if b_squared &lt; 0:\n                a += 1\n                continue\n\n            b = math.isqrt(b_squared)\n\n            if b * b == b_squared:\n                p = a - b\n                q = a + b\n                if p * q == self.n and p &gt; 1 and q &gt; 1:\n                    if self.verbose:\n                        print(f\"Fermat found factors: p = {p}, q = {q}\")\n                    else:\n                        print(f\"Fermat found factors: p = {p}, q = (use verbose mode)\")\n                    self.p, self.q = p, q\n                    return p, q\n\n            a += 1\n\n        print(\"Fermat factorization failed\")\n        return None\n\n    def calculate_private_key(self) -&gt; Optional[int]:\n        \"\"\"Calculate private key from known factors.\n\n        Returns:\n            Private exponent d if successful, None otherwise\n        \"\"\"\n        if not (self.p and self.q):\n            print(\"Need factors p and q to calculate private key\")\n            return None\n\n        phi = (self.p - 1) * (self.q - 1)\n\n        try:\n            self.d = inverse(self.e, phi)\n            if self.verbose:\n                print(f\"Calculated private key: d = {self.d}\")\n                return self.d\n            else:\n                print(\"Calculated private key: d = (use verbose mode)\")\n                return self.d\n        except ValueError as e:\n            print(f\"Failed to calculate private key: {e}\")\n            return None\n\n    def decrypt(self) -&gt; Optional[bytes]:\n        \"\"\"Decrypt the ciphertext using the private key.\n\n        Returns:\n            Decrypted message as bytes if successful, None otherwise\n        \"\"\"\n        if not self.d:\n            print(\"Private key not available for decryption\")\n            return None\n\n        try:\n            plaintext_int = pow(self.ciphertext, self.d, self.n)\n            plaintext_bytes: bytes = long_to_bytes(plaintext_int)\n        except Exception as e:\n            print(f\"Decryption failed: {e}\")\n            return None\n        else:\n            if self.verbose:\n                print(f\"Decrypted message: {plaintext_bytes!r}\")\n            return plaintext_bytes\n\n    def small_exponent_attack(self) -&gt; Optional[bytes]:\n        \"\"\"Attempt small exponent attack (when e is small and message^e &lt; n).\n\n        Returns:\n            Decrypted message if successful, None otherwise\n        \"\"\"\n        if self.e &gt;= 10:  # Only try for very small exponents\n            return None\n\n        print(f\"Attempting small exponent attack with e = {self.e}\")\n\n        # Try taking the eth root directly\n        for k in range(100):  # Try different k values\n            potential_message = int(pow(self.ciphertext + k * self.n, 1 / self.e))\n\n            if pow(potential_message, self.e) == self.ciphertext:\n                try:\n                    plaintext_bytes: bytes = long_to_bytes(potential_message)\n                except (ValueError, OverflowError):\n                    continue\n                else:\n                    print(f\"Small exponent attack successful: {plaintext_bytes!r}\")\n                    return plaintext_bytes\n\n        print(\"Small exponent attack failed\")\n        return None\n\n    def auto_decrypt(self) -&gt; Optional[bytes]:\n        \"\"\"Automatically try various attack methods in order of likelihood.\n\n        Returns:\n            Decrypted message if any method succeeds, None otherwise\n        \"\"\"\n        # Method 1: FactorDB lookup (fastest for known factorizations)\n        factors = self.factordb_lookup()\n        if factors:\n            self.calculate_private_key()\n            return self.decrypt()\n\n        # Method 2: Small exponent attack\n        result = self.small_exponent_attack()\n        if result:\n            return result\n\n        # Method 3: Small prime factorization\n        factors = self.factor_small_primes()\n        if factors:\n            self.calculate_private_key()\n            return self.decrypt()\n\n        # Method 4: Pollard's rho\n        factors = self.pollards_rho()\n        if factors:\n            self.calculate_private_key()\n            return self.decrypt()\n\n        # Method 5: Fermat factorization\n        factors = self.fermat_factorization()\n        if factors:\n            self.calculate_private_key()\n            return self.decrypt()\n\n        print(\"All decryption methods failed\")\n        return None\n</code></pre>"},{"location":"reference/ciphergeist/decrypters/rsa_decrypter/#ciphergeist.decrypters.rsa_decrypter.RSADecrypter.__init__","title":"<code>__init__(n, e, ciphertext, verbose=False)</code>","text":"<p>Initialize RSA decrypter with public parameters and ciphertext.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>Public modulus</p> required <code>e</code> <code>int</code> <p>Public exponent</p> required <code>ciphertext</code> <code>int</code> <p>Encrypted message</p> required <code>verbose</code> <code>bool</code> <p>Whether to print detailed information (default False)</p> <code>False</code> Source code in <code>src/ciphergeist/decrypters/rsa_decrypter.py</code> <pre><code>def __init__(self, n: int, e: int, ciphertext: int, verbose: bool = False):\n    \"\"\"Initialize RSA decrypter with public parameters and ciphertext.\n\n    Args:\n        n: Public modulus\n        e: Public exponent\n        ciphertext: Encrypted message\n        verbose: Whether to print detailed information (default False)\n    \"\"\"\n    self.n = n\n    self.e = e\n    self.ciphertext = ciphertext\n    self.p: Optional[int] = None\n    self.q: Optional[int] = None\n    self.d: Optional[int] = None\n    self.verbose = verbose\n</code></pre>"},{"location":"reference/ciphergeist/decrypters/rsa_decrypter/#ciphergeist.decrypters.rsa_decrypter.RSADecrypter.auto_decrypt","title":"<code>auto_decrypt()</code>","text":"<p>Automatically try various attack methods in order of likelihood.</p> <p>Returns:</p> Type Description <code>Optional[bytes]</code> <p>Decrypted message if any method succeeds, None otherwise</p> Source code in <code>src/ciphergeist/decrypters/rsa_decrypter.py</code> <pre><code>def auto_decrypt(self) -&gt; Optional[bytes]:\n    \"\"\"Automatically try various attack methods in order of likelihood.\n\n    Returns:\n        Decrypted message if any method succeeds, None otherwise\n    \"\"\"\n    # Method 1: FactorDB lookup (fastest for known factorizations)\n    factors = self.factordb_lookup()\n    if factors:\n        self.calculate_private_key()\n        return self.decrypt()\n\n    # Method 2: Small exponent attack\n    result = self.small_exponent_attack()\n    if result:\n        return result\n\n    # Method 3: Small prime factorization\n    factors = self.factor_small_primes()\n    if factors:\n        self.calculate_private_key()\n        return self.decrypt()\n\n    # Method 4: Pollard's rho\n    factors = self.pollards_rho()\n    if factors:\n        self.calculate_private_key()\n        return self.decrypt()\n\n    # Method 5: Fermat factorization\n    factors = self.fermat_factorization()\n    if factors:\n        self.calculate_private_key()\n        return self.decrypt()\n\n    print(\"All decryption methods failed\")\n    return None\n</code></pre>"},{"location":"reference/ciphergeist/decrypters/rsa_decrypter/#ciphergeist.decrypters.rsa_decrypter.RSADecrypter.calculate_private_key","title":"<code>calculate_private_key()</code>","text":"<p>Calculate private key from known factors.</p> <p>Returns:</p> Type Description <code>Optional[int]</code> <p>Private exponent d if successful, None otherwise</p> Source code in <code>src/ciphergeist/decrypters/rsa_decrypter.py</code> <pre><code>def calculate_private_key(self) -&gt; Optional[int]:\n    \"\"\"Calculate private key from known factors.\n\n    Returns:\n        Private exponent d if successful, None otherwise\n    \"\"\"\n    if not (self.p and self.q):\n        print(\"Need factors p and q to calculate private key\")\n        return None\n\n    phi = (self.p - 1) * (self.q - 1)\n\n    try:\n        self.d = inverse(self.e, phi)\n        if self.verbose:\n            print(f\"Calculated private key: d = {self.d}\")\n            return self.d\n        else:\n            print(\"Calculated private key: d = (use verbose mode)\")\n            return self.d\n    except ValueError as e:\n        print(f\"Failed to calculate private key: {e}\")\n        return None\n</code></pre>"},{"location":"reference/ciphergeist/decrypters/rsa_decrypter/#ciphergeist.decrypters.rsa_decrypter.RSADecrypter.decrypt","title":"<code>decrypt()</code>","text":"<p>Decrypt the ciphertext using the private key.</p> <p>Returns:</p> Type Description <code>Optional[bytes]</code> <p>Decrypted message as bytes if successful, None otherwise</p> Source code in <code>src/ciphergeist/decrypters/rsa_decrypter.py</code> <pre><code>def decrypt(self) -&gt; Optional[bytes]:\n    \"\"\"Decrypt the ciphertext using the private key.\n\n    Returns:\n        Decrypted message as bytes if successful, None otherwise\n    \"\"\"\n    if not self.d:\n        print(\"Private key not available for decryption\")\n        return None\n\n    try:\n        plaintext_int = pow(self.ciphertext, self.d, self.n)\n        plaintext_bytes: bytes = long_to_bytes(plaintext_int)\n    except Exception as e:\n        print(f\"Decryption failed: {e}\")\n        return None\n    else:\n        if self.verbose:\n            print(f\"Decrypted message: {plaintext_bytes!r}\")\n        return plaintext_bytes\n</code></pre>"},{"location":"reference/ciphergeist/decrypters/rsa_decrypter/#ciphergeist.decrypters.rsa_decrypter.RSADecrypter.factor_small_primes","title":"<code>factor_small_primes(max_prime=10000)</code>","text":"<p>Attempt to factor n by testing small prime factors.</p> <p>Parameters:</p> Name Type Description Default <code>max_prime</code> <code>int</code> <p>Maximum prime to test (default 10000)</p> <code>10000</code> <p>Returns:</p> Type Description <code>Optional[tuple[int, int]]</code> <p>Tuple of (p, q) if factorization found, None otherwise</p> Source code in <code>src/ciphergeist/decrypters/rsa_decrypter.py</code> <pre><code>def factor_small_primes(self, max_prime: int = 10000) -&gt; Optional[tuple[int, int]]:\n    \"\"\"Attempt to factor n by testing small prime factors.\n\n    Args:\n        max_prime: Maximum prime to test (default 10000)\n\n    Returns:\n        Tuple of (p, q) if factorization found, None otherwise\n    \"\"\"\n    print(f\"Attempting to factor n with small primes up to {max_prime}...\")\n\n    # Test small prime factors\n    # Use a more efficient approach for very large numbers\n    sqrt_limit = min(max_prime, 100000)  # Cap the search to avoid overflow\n\n    for i in range(2, sqrt_limit):\n        if self.n % i == 0:\n            p = i\n            q = self.n // i\n            if self.verbose:\n                print(f\"Found factors: p = {p}, q = {q}\")\n            else:\n                print(f\"Found factors: p = {p}, q = (use verbose mode)\")\n            self.p, self.q = p, q\n            return p, q\n\n    print(\"No small prime factors found\")\n    return None\n</code></pre>"},{"location":"reference/ciphergeist/decrypters/rsa_decrypter/#ciphergeist.decrypters.rsa_decrypter.RSADecrypter.factordb_lookup","title":"<code>factordb_lookup()</code>","text":"<p>Query FactorDB.com for known factorizations.</p> <p>Returns:</p> Type Description <code>Optional[tuple[int, int]]</code> <p>Tuple of (p, q) if factorization found, None otherwise</p> Source code in <code>src/ciphergeist/decrypters/rsa_decrypter.py</code> <pre><code>def factordb_lookup(self) -&gt; Optional[tuple[int, int]]:\n    \"\"\"Query FactorDB.com for known factorizations.\n\n    Returns:\n        Tuple of (p, q) if factorization found, None otherwise\n    \"\"\"\n    if not HTTPX_AVAILABLE:\n        if self.verbose:\n            print(\"FactorDB lookup skipped: httpx not available\")\n        return None\n\n    print(\"Checking FactorDB.com for known factorization...\")\n\n    try:\n        url = f\"https://factordb.com/api?query={self.n}\"\n        response = httpx.get(url, timeout=10.0)\n\n        if response.status_code != 200:\n            print(\"FactorDB lookup failed: HTTP error\")\n            return None\n\n        data = response.json()\n\n        # Check if the number is factored\n        if data.get(\"status\") == \"FF\":  # Fully Factored\n            return self._extract_rsa_factors(data)\n        else:\n            print(\"FactorDB: Number not fully factored\")\n            return None\n\n    except Exception as e:\n        if self.verbose:\n            print(f\"FactorDB lookup failed: {e}\")\n        else:\n            print(\"FactorDB lookup failed\")\n        return None\n</code></pre>"},{"location":"reference/ciphergeist/decrypters/rsa_decrypter/#ciphergeist.decrypters.rsa_decrypter.RSADecrypter.fermat_factorization","title":"<code>fermat_factorization(max_iterations=100000)</code>","text":"<p>Fermat's factorization method (works well when p and q are close).</p> <p>Parameters:</p> Name Type Description Default <code>max_iterations</code> <code>int</code> <p>Maximum iterations to attempt</p> <code>100000</code> <p>Returns:</p> Type Description <code>Optional[tuple[int, int]]</code> <p>Tuple of (p, q) if factorization found, None otherwise</p> Source code in <code>src/ciphergeist/decrypters/rsa_decrypter.py</code> <pre><code>def fermat_factorization(self, max_iterations: int = 100000) -&gt; Optional[tuple[int, int]]:\n    \"\"\"Fermat's factorization method (works well when p and q are close).\n\n    Args:\n        max_iterations: Maximum iterations to attempt\n\n    Returns:\n        Tuple of (p, q) if factorization found, None otherwise\n    \"\"\"\n    print(\"Attempting Fermat factorization...\")\n\n    a = math.isqrt(self.n) + 1\n\n    for _ in range(max_iterations):\n        b_squared = a * a - self.n\n        if b_squared &lt; 0:\n            a += 1\n            continue\n\n        b = math.isqrt(b_squared)\n\n        if b * b == b_squared:\n            p = a - b\n            q = a + b\n            if p * q == self.n and p &gt; 1 and q &gt; 1:\n                if self.verbose:\n                    print(f\"Fermat found factors: p = {p}, q = {q}\")\n                else:\n                    print(f\"Fermat found factors: p = {p}, q = (use verbose mode)\")\n                self.p, self.q = p, q\n                return p, q\n\n        a += 1\n\n    print(\"Fermat factorization failed\")\n    return None\n</code></pre>"},{"location":"reference/ciphergeist/decrypters/rsa_decrypter/#ciphergeist.decrypters.rsa_decrypter.RSADecrypter.pollards_rho","title":"<code>pollards_rho(max_iterations=100000)</code>","text":"<p>Pollard's rho algorithm for factorization.</p> <p>Parameters:</p> Name Type Description Default <code>max_iterations</code> <code>int</code> <p>Maximum iterations to attempt</p> <code>100000</code> <p>Returns:</p> Type Description <code>Optional[tuple[int, int]]</code> <p>Tuple of (p, q) if factorization found, None otherwise</p> Source code in <code>src/ciphergeist/decrypters/rsa_decrypter.py</code> <pre><code>def pollards_rho(self, max_iterations: int = 100000) -&gt; Optional[tuple[int, int]]:\n    \"\"\"Pollard's rho algorithm for factorization.\n\n    Args:\n        max_iterations: Maximum iterations to attempt\n\n    Returns:\n        Tuple of (p, q) if factorization found, None otherwise\n    \"\"\"\n    print(\"Attempting Pollard's rho factorization...\")\n\n    def f(x: int) -&gt; int:\n        return (x * x + 1) % self.n\n\n    x = 2\n    y = 2\n\n    for _ in range(max_iterations):\n        x = f(x)\n        y = f(f(y))\n\n        gcd_val = GCD(abs(x - y), self.n)\n\n        if 1 &lt; gcd_val &lt; self.n:\n            p = gcd_val\n            q = self.n // p\n            if self.verbose:\n                print(f\"Pollard's rho found factors: p = {p}, q = {q}\")\n            else:\n                print(f\"Pollard's rho found factors: p = {p}, q = (use verbose mode)\")\n            self.p, self.q = p, q\n            return p, q\n\n    print(\"Pollard's rho failed to find factors\")\n    return None\n</code></pre>"},{"location":"reference/ciphergeist/decrypters/rsa_decrypter/#ciphergeist.decrypters.rsa_decrypter.RSADecrypter.small_exponent_attack","title":"<code>small_exponent_attack()</code>","text":"<p>Attempt small exponent attack (when e is small and message^e &lt; n).</p> <p>Returns:</p> Type Description <code>Optional[bytes]</code> <p>Decrypted message if successful, None otherwise</p> Source code in <code>src/ciphergeist/decrypters/rsa_decrypter.py</code> <pre><code>def small_exponent_attack(self) -&gt; Optional[bytes]:\n    \"\"\"Attempt small exponent attack (when e is small and message^e &lt; n).\n\n    Returns:\n        Decrypted message if successful, None otherwise\n    \"\"\"\n    if self.e &gt;= 10:  # Only try for very small exponents\n        return None\n\n    print(f\"Attempting small exponent attack with e = {self.e}\")\n\n    # Try taking the eth root directly\n    for k in range(100):  # Try different k values\n        potential_message = int(pow(self.ciphertext + k * self.n, 1 / self.e))\n\n        if pow(potential_message, self.e) == self.ciphertext:\n            try:\n                plaintext_bytes: bytes = long_to_bytes(potential_message)\n            except (ValueError, OverflowError):\n                continue\n            else:\n                print(f\"Small exponent attack successful: {plaintext_bytes!r}\")\n                return plaintext_bytes\n\n    print(\"Small exponent attack failed\")\n    return None\n</code></pre>"},{"location":"reference/ciphergeist/encoders/","title":"Index","text":""},{"location":"reference/ciphergeist/encoders/pixelator/","title":"pixelator","text":""},{"location":"reference/ciphergeist/encoders/pixelator/#ciphergeist.encoders.pixelator.ChunkInfo","title":"<code>ChunkInfo</code>  <code>dataclass</code>","text":"<p>Information about a data chunk.</p> Source code in <code>src/ciphergeist/encoders/pixelator.py</code> <pre><code>@dataclass\nclass ChunkInfo:\n    \"\"\"Information about a data chunk.\"\"\"\n\n    chunk_id: int\n    image_name: str\n    data_bytes: int\n    chunk_hash: str\n</code></pre>"},{"location":"reference/ciphergeist/encoders/pixelator/#ciphergeist.encoders.pixelator.EncodingResult","title":"<code>EncodingResult</code>  <code>dataclass</code>","text":"<p>Result of document encoding process.</p> Source code in <code>src/ciphergeist/encoders/pixelator.py</code> <pre><code>@dataclass\nclass EncodingResult:\n    \"\"\"Result of document encoding process.\"\"\"\n\n    metadata_image: str\n    chunk_images: list[str]\n    total_size: int\n    chunk_count: int\n</code></pre>"},{"location":"reference/ciphergeist/encoders/pixelator/#ciphergeist.encoders.pixelator.Pixelator","title":"<code>Pixelator</code>","text":"<p>Document-to-Image encoder with optional encryption and metadata management.</p> <p>Converts documents to image files with comprehensive metadata tracking and recovery capabilities. Supports optional XOR encryption.</p> Source code in <code>src/ciphergeist/encoders/pixelator.py</code> <pre><code>class Pixelator:\n    \"\"\"\n    Document-to-Image encoder with optional encryption and metadata management.\n\n    Converts documents to image files with comprehensive metadata\n    tracking and recovery capabilities. Supports optional XOR encryption.\n    \"\"\"\n\n    IMAGE_WIDTH = 160\n    IMAGE_HEIGHT = 125\n    IMAGE_CHANNELS = 3\n    ERROR_CORRECTION_RATIO = 0.2\n    CHUNK_OVERLAP_BYTES = 2**7  # 128 bytes overlap for error recovery\n\n    def __init__(self, encryption_key: Optional[str] = None) -&gt; None:\n        \"\"\"\n        Initialize Pixelator.\n\n        Args:\n            encryption_key: Optional XOR encryption key. If None, no encryption is used.\n        \"\"\"\n        self.encryption_key = encryption_key\n        self._magic = magic.Magic(mime=True)\n        self._http_client = httpx.AsyncClient(timeout=10.0)\n        self.image_capacity = self.IMAGE_WIDTH * self.IMAGE_HEIGHT * self.IMAGE_CHANNELS\n        self.chunk_size = self._calculate_optimal_chunk_size()\n\n    def _calculate_optimal_chunk_size(self) -&gt; int:\n        \"\"\"\n        Calculate the maximum data chunk size that can fit in an image\n        after accounting for recovery overhead.\n        \"\"\"\n        # Formula: Capacity = Chunk + (Chunk * ErrorRatio) + Overlap\n        # Rearranged: Capacity - Overlap = Chunk * (1 + ErrorRatio)\n        # Therefore: Chunk = (Capacity - Overlap) / (1 + ErrorRatio)\n\n        usable_capacity = self.image_capacity - self.CHUNK_OVERLAP_BYTES\n        optimal_size = usable_capacity / (1 + self.ERROR_CORRECTION_RATIO)\n\n        # Return as an integer, ensuring it's a multiple of 8 for clean boundaries\n        return int(optimal_size // 8 * 8)\n\n    def _xor_encrypt_decrypt(self, data: bytes, key: str) -&gt; bytes:\n        \"\"\"XOR encrypt/decrypt data with a repeating key.\"\"\"\n        if not key:\n            return data\n\n        key_bytes = key.encode(\"utf-8\")\n        result = bytearray()\n        key_len = len(key_bytes)\n\n        for i, byte in enumerate(data):\n            result.append(byte ^ key_bytes[i % key_len])\n\n        return bytes(result)\n\n    def _check_chunk_exists(self, chunk_path: Path, image_name: str) -&gt; None:\n        \"\"\"Check if chunk file exists and raise error if not.\"\"\"\n        if not chunk_path.exists():\n            raise FileNotFoundError(f\"Chunk image not found: {image_name}\")\n\n    def _verify_chunk_integrity(self, chunk_data: bytes, expected_hash: str, image_name: str) -&gt; None:\n        \"\"\"Verify chunk integrity and raise error if invalid.\"\"\"\n        chunk_hash = self._calculate_hash(chunk_data)\n        if chunk_hash != expected_hash:\n            raise ValueError(f\"Chunk integrity check failed: {image_name}\")\n\n    async def encode_document(\n        self, file_path: Union[str, Path], output_dir: Union[str, Path] = \"output\"\n    ) -&gt; EncodingResult:\n        \"\"\"\n        Encode document to images with optional encryption.\n\n        Args:\n            file_path: Path to document to encode\n            output_dir: Directory to save encoded images\n\n        Returns:\n            EncodingResult with metadata and image information\n\n        Raises:\n            FileNotFoundError: If input file doesn't exist\n            ValueError: If file cannot be processed\n        \"\"\"\n        file_path = Path(file_path)\n        output_dir = Path(output_dir)\n        output_dir.mkdir(exist_ok=True)\n\n        # Step 1: Process document\n        document_data, file_metadata = self._process_document(file_path)\n\n        # Step 2: Optionally encrypt data\n        if self.encryption_key:\n            encrypted_data = self._xor_encrypt_decrypt(document_data, self.encryption_key)\n        else:\n            encrypted_data = document_data\n\n        # Step 3: Create chunks\n        chunks = self._create_chunks(encrypted_data)\n\n        # Step 4: Generate image names\n        chunk_names = await self._generate_image_names(len(chunks))\n\n        # Create metadata image name based on document name\n        document_name = file_path.stem  # Get filename without extension\n        metadata_image_name = f\"{document_name}_metadata.png\"\n\n        # Step 5: Create chunk images\n        chunk_infos = []\n        chunk_images = []\n\n        for i, (chunk_data, filename) in enumerate(zip(chunks, chunk_names)):\n            chunk_hash = self._calculate_hash(chunk_data)\n            image_path = output_dir / filename\n\n            self._encode_data_to_image(chunk_data, image_path)\n\n            chunk_infos.append(\n                ChunkInfo(chunk_id=i, image_name=filename, data_bytes=len(chunk_data), chunk_hash=chunk_hash)\n            )\n            chunk_images.append(filename)\n\n        # Step 6: Create metadata\n        metadata = self._create_metadata(file_metadata, chunk_infos, encrypted_data)\n\n        # Step 7: Create metadata image\n        metadata_path = output_dir / metadata_image_name\n        metadata_json = json.dumps(metadata, indent=2).encode(\"utf-8\")\n\n        self._encode_data_to_image(metadata_json, metadata_path)\n\n        return EncodingResult(\n            metadata_image=metadata_image_name,\n            chunk_images=chunk_images,\n            total_size=len(encrypted_data),\n            chunk_count=len(chunks),\n        )\n\n    async def decode_document(\n        self,\n        metadata_image_path: Union[str, Path],\n        output_path: Union[str, Path],\n        images_dir: Optional[Union[str, Path]] = None,\n    ) -&gt; bool:\n        \"\"\"\n        Decode document from images with optional decryption.\n\n        Args:\n            metadata_image_path: Path to metadata image\n            output_path: Path where to save decoded document\n            images_dir: Directory containing chunk images (default: same as metadata)\n\n        Returns:\n            True if successful, False otherwise\n        \"\"\"\n        metadata_image_path = Path(metadata_image_path)\n        output_path = Path(output_path)\n\n        images_dir = metadata_image_path.parent if images_dir is None else Path(images_dir)\n\n        try:\n            # Step 1: Decode metadata\n            metadata_data = self._decode_data_from_image(metadata_image_path)\n            metadata = json.loads(metadata_data.decode(\"utf-8\"))\n\n            # Step 2: Collect chunks\n            chunks_data = []\n            chunk_infos = metadata[\"chunks\"][\"images\"]\n\n            for image_name, chunk_info in chunk_infos.items():\n                chunk_path = images_dir / image_name\n                self._check_chunk_exists(chunk_path, image_name)\n\n                chunk_data = self._decode_data_from_image(chunk_path)\n                expected_size = chunk_info[\"data_bytes\"]\n                chunk_data = chunk_data[:expected_size]  # Trim to exact size\n\n                # Verify chunk integrity\n                self._verify_chunk_integrity(chunk_data, chunk_info[\"chunk_hash\"], image_name)\n\n                chunks_data.append((chunk_info[\"chunk_id\"], chunk_data))\n\n            # Step 3: Reassemble data\n            chunks_data.sort(key=lambda x: x[0])  # Sort by chunk_id\n            assembled_data = b\"\".join(chunk[1] for chunk in chunks_data)\n\n            # Step 4: Optionally decrypt data\n            if self.encryption_key and metadata.get(\"encryption\", {}).get(\"algorithm\") == \"xor\":\n                document_data = self._xor_encrypt_decrypt(assembled_data, self.encryption_key)\n            else:\n                document_data = assembled_data\n\n            # Step 5: Decompress and save\n            original_data = lzma.decompress(document_data)\n            output_path.write_bytes(original_data)\n\n        except Exception as e:\n            print(f\"Decoding failed: {e}\")\n            return False\n        else:\n            return True\n\n    def _process_document(self, file_path: Path) -&gt; tuple[bytes, dict[str, Any]]:\n        \"\"\"Process document and generate metadata.\"\"\"\n        if not file_path.exists():\n            raise FileNotFoundError(f\"Document not found: {file_path}\")\n\n        original_data = file_path.read_bytes()\n        file_extension, mime_type = self._detect_file_type(file_path)\n        compressed_data = lzma.compress(original_data, preset=6)\n\n        metadata = {\n            \"filename\": file_path.name,\n            \"extension\": file_extension,\n            \"mime_type\": mime_type,\n            \"original_size\": len(original_data),\n            \"compressed_size\": len(compressed_data),\n            \"hash\": self._calculate_hash(original_data),\n        }\n\n        return compressed_data, metadata\n\n    def _detect_file_type(self, file_path: Path) -&gt; tuple[str, str]:\n        \"\"\"Detect file type and MIME type.\"\"\"\n        try:\n            mime_type = self._magic.from_file(str(file_path))\n        except Exception:\n            guessed_mime_type, _ = mimetypes.guess_type(str(file_path))\n            mime_type = guessed_mime_type or \"application/octet-stream\"\n\n        # Get extension\n        if file_path.suffix:\n            extension = file_path.suffix.lower()\n        else:\n            guessed_extension = mimetypes.guess_extension(mime_type)\n            extension = guessed_extension if guessed_extension else \".bin\"\n\n        return extension, mime_type\n\n    def _create_chunks(self, data: bytes) -&gt; list[bytes]:\n        \"\"\"Split data into chunks.\"\"\"\n        chunks = []\n        for i in range(0, len(data), self.chunk_size):\n            chunk = data[i : i + self.chunk_size]\n            chunks.append(chunk)\n        return chunks\n\n    async def _generate_image_names(self, count: int) -&gt; list[str]:\n        \"\"\"Generate random filenames for images.\"\"\"\n        names = []\n        for _ in range(count):\n            try:\n                # Try to get random name from API\n                response = await self._http_client.get(\"https://randomuser.me/api/?inc=email\")\n                response.raise_for_status()\n\n                data = response.json()\n                name_data = data[\"results\"][0][\"email\"].split(\"@\")[0]\n                filename = f\"{name_data}.png\"\n                # strip al non-alphanumeric characters\n\n                names.append(filename)\n\n            except Exception:\n                filename = f\"{uuid.uuid4().hex}.png\"\n                names.append(filename)\n\n        return names\n\n    def _encode_data_to_image(self, data: bytes, output_path: Path) -&gt; None:\n        \"\"\"Encode binary data into PNG image.\"\"\"\n        # Calculate required pixels\n        data_length = len(data)\n        total_pixels = self.IMAGE_WIDTH * self.IMAGE_HEIGHT\n        max_capacity = total_pixels * self.IMAGE_CHANNELS\n\n        if data_length &gt; max_capacity:\n            raise ValueError(f\"Data too large: {data_length} &gt; {max_capacity}\")\n\n        # Pad data to fill image if needed\n        padded_data = data + b\"\\x00\" * (max_capacity - data_length)\n\n        # Convert to numpy array and reshape\n        data_array = np.frombuffer(padded_data, dtype=np.uint8)\n        image_array = data_array.reshape((self.IMAGE_HEIGHT, self.IMAGE_WIDTH, self.IMAGE_CHANNELS))\n\n        # Create and save image\n        image = Image.fromarray(image_array, \"RGB\")\n        image.save(output_path, \"PNG\")\n\n    def _decode_data_from_image(self, image_path: Path) -&gt; bytes:\n        \"\"\"Decode binary data from PNG image.\"\"\"\n        # Load image\n        image = Image.open(image_path)\n        image_array = np.array(image)\n\n        # Flatten to bytes\n        data_bytes: bytes = image_array.flatten().tobytes()\n\n        return data_bytes\n\n    def _create_metadata(\n        self, file_metadata: dict[str, Any], chunk_infos: list[ChunkInfo], processed_data: bytes\n    ) -&gt; dict[str, Any]:\n        \"\"\"Create comprehensive metadata structure.\"\"\"\n        chunks_dict = {}\n        for chunk_info in chunk_infos:\n            chunks_dict[chunk_info.image_name] = {\n                \"chunk_id\": chunk_info.chunk_id,\n                \"data_bytes\": chunk_info.data_bytes,\n                \"chunk_hash\": chunk_info.chunk_hash,\n            }\n\n        metadata = {\n            \"version\": \"1.0.0\",\n            \"document\": {\n                \"filename\": file_metadata[\"filename\"],\n                \"extension\": file_metadata[\"extension\"],\n                \"mime_type\": file_metadata[\"mime_type\"],\n                \"original_size\": file_metadata[\"original_size\"],\n                \"compressed_size\": file_metadata[\"compressed_size\"],\n                \"hash\": file_metadata[\"hash\"],\n            },\n            \"chunks\": {\n                \"total\": len(chunk_infos),\n                \"chunk_size\": self.chunk_size,\n                \"total_processed_size\": len(processed_data),\n                \"images\": chunks_dict,\n            },\n            \"recovery\": {\n                \"error_correction_ratio\": self.ERROR_CORRECTION_RATIO,\n                \"chunk_overlap_bytes\": self.CHUNK_OVERLAP_BYTES,\n            },\n        }\n\n        # Add encryption info if key is used\n        if self.encryption_key:\n            metadata[\"encryption\"] = {\n                \"algorithm\": \"xor\",\n                \"encrypted\": True,\n            }\n        else:\n            metadata[\"encryption\"] = {\n                \"algorithm\": \"none\",\n                \"encrypted\": False,\n            }\n\n        return metadata\n\n    def _calculate_hash(self, data: bytes) -&gt; str:\n        \"\"\"Calculate SHA-256 hash.\"\"\"\n        return hashlib.sha256(data).hexdigest()\n\n    async def close(self) -&gt; None:\n        \"\"\"Clean up resources.\"\"\"\n        await self._http_client.aclose()\n\n    async def __aenter__(self) -&gt; \"Pixelator\":\n        \"\"\"Async context manager entry.\"\"\"\n        return self\n\n    async def __aexit__(self, exc_type: Any, exc_val: Any, exc_tb: Any) -&gt; None:\n        \"\"\"Async context manager exit.\"\"\"\n        await self.close()\n</code></pre>"},{"location":"reference/ciphergeist/encoders/pixelator/#ciphergeist.encoders.pixelator.Pixelator.__aenter__","title":"<code>__aenter__()</code>  <code>async</code>","text":"<p>Async context manager entry.</p> Source code in <code>src/ciphergeist/encoders/pixelator.py</code> <pre><code>async def __aenter__(self) -&gt; \"Pixelator\":\n    \"\"\"Async context manager entry.\"\"\"\n    return self\n</code></pre>"},{"location":"reference/ciphergeist/encoders/pixelator/#ciphergeist.encoders.pixelator.Pixelator.__aexit__","title":"<code>__aexit__(exc_type, exc_val, exc_tb)</code>  <code>async</code>","text":"<p>Async context manager exit.</p> Source code in <code>src/ciphergeist/encoders/pixelator.py</code> <pre><code>async def __aexit__(self, exc_type: Any, exc_val: Any, exc_tb: Any) -&gt; None:\n    \"\"\"Async context manager exit.\"\"\"\n    await self.close()\n</code></pre>"},{"location":"reference/ciphergeist/encoders/pixelator/#ciphergeist.encoders.pixelator.Pixelator.__init__","title":"<code>__init__(encryption_key=None)</code>","text":"<p>Initialize Pixelator.</p> <p>Parameters:</p> Name Type Description Default <code>encryption_key</code> <code>Optional[str]</code> <p>Optional XOR encryption key. If None, no encryption is used.</p> <code>None</code> Source code in <code>src/ciphergeist/encoders/pixelator.py</code> <pre><code>def __init__(self, encryption_key: Optional[str] = None) -&gt; None:\n    \"\"\"\n    Initialize Pixelator.\n\n    Args:\n        encryption_key: Optional XOR encryption key. If None, no encryption is used.\n    \"\"\"\n    self.encryption_key = encryption_key\n    self._magic = magic.Magic(mime=True)\n    self._http_client = httpx.AsyncClient(timeout=10.0)\n    self.image_capacity = self.IMAGE_WIDTH * self.IMAGE_HEIGHT * self.IMAGE_CHANNELS\n    self.chunk_size = self._calculate_optimal_chunk_size()\n</code></pre>"},{"location":"reference/ciphergeist/encoders/pixelator/#ciphergeist.encoders.pixelator.Pixelator.close","title":"<code>close()</code>  <code>async</code>","text":"<p>Clean up resources.</p> Source code in <code>src/ciphergeist/encoders/pixelator.py</code> <pre><code>async def close(self) -&gt; None:\n    \"\"\"Clean up resources.\"\"\"\n    await self._http_client.aclose()\n</code></pre>"},{"location":"reference/ciphergeist/encoders/pixelator/#ciphergeist.encoders.pixelator.Pixelator.decode_document","title":"<code>decode_document(metadata_image_path, output_path, images_dir=None)</code>  <code>async</code>","text":"<p>Decode document from images with optional decryption.</p> <p>Parameters:</p> Name Type Description Default <code>metadata_image_path</code> <code>Union[str, Path]</code> <p>Path to metadata image</p> required <code>output_path</code> <code>Union[str, Path]</code> <p>Path where to save decoded document</p> required <code>images_dir</code> <code>Optional[Union[str, Path]]</code> <p>Directory containing chunk images (default: same as metadata)</p> <code>None</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if successful, False otherwise</p> Source code in <code>src/ciphergeist/encoders/pixelator.py</code> <pre><code>async def decode_document(\n    self,\n    metadata_image_path: Union[str, Path],\n    output_path: Union[str, Path],\n    images_dir: Optional[Union[str, Path]] = None,\n) -&gt; bool:\n    \"\"\"\n    Decode document from images with optional decryption.\n\n    Args:\n        metadata_image_path: Path to metadata image\n        output_path: Path where to save decoded document\n        images_dir: Directory containing chunk images (default: same as metadata)\n\n    Returns:\n        True if successful, False otherwise\n    \"\"\"\n    metadata_image_path = Path(metadata_image_path)\n    output_path = Path(output_path)\n\n    images_dir = metadata_image_path.parent if images_dir is None else Path(images_dir)\n\n    try:\n        # Step 1: Decode metadata\n        metadata_data = self._decode_data_from_image(metadata_image_path)\n        metadata = json.loads(metadata_data.decode(\"utf-8\"))\n\n        # Step 2: Collect chunks\n        chunks_data = []\n        chunk_infos = metadata[\"chunks\"][\"images\"]\n\n        for image_name, chunk_info in chunk_infos.items():\n            chunk_path = images_dir / image_name\n            self._check_chunk_exists(chunk_path, image_name)\n\n            chunk_data = self._decode_data_from_image(chunk_path)\n            expected_size = chunk_info[\"data_bytes\"]\n            chunk_data = chunk_data[:expected_size]  # Trim to exact size\n\n            # Verify chunk integrity\n            self._verify_chunk_integrity(chunk_data, chunk_info[\"chunk_hash\"], image_name)\n\n            chunks_data.append((chunk_info[\"chunk_id\"], chunk_data))\n\n        # Step 3: Reassemble data\n        chunks_data.sort(key=lambda x: x[0])  # Sort by chunk_id\n        assembled_data = b\"\".join(chunk[1] for chunk in chunks_data)\n\n        # Step 4: Optionally decrypt data\n        if self.encryption_key and metadata.get(\"encryption\", {}).get(\"algorithm\") == \"xor\":\n            document_data = self._xor_encrypt_decrypt(assembled_data, self.encryption_key)\n        else:\n            document_data = assembled_data\n\n        # Step 5: Decompress and save\n        original_data = lzma.decompress(document_data)\n        output_path.write_bytes(original_data)\n\n    except Exception as e:\n        print(f\"Decoding failed: {e}\")\n        return False\n    else:\n        return True\n</code></pre>"},{"location":"reference/ciphergeist/encoders/pixelator/#ciphergeist.encoders.pixelator.Pixelator.encode_document","title":"<code>encode_document(file_path, output_dir='output')</code>  <code>async</code>","text":"<p>Encode document to images with optional encryption.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>Union[str, Path]</code> <p>Path to document to encode</p> required <code>output_dir</code> <code>Union[str, Path]</code> <p>Directory to save encoded images</p> <code>'output'</code> <p>Returns:</p> Type Description <code>EncodingResult</code> <p>EncodingResult with metadata and image information</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If input file doesn't exist</p> <code>ValueError</code> <p>If file cannot be processed</p> Source code in <code>src/ciphergeist/encoders/pixelator.py</code> <pre><code>async def encode_document(\n    self, file_path: Union[str, Path], output_dir: Union[str, Path] = \"output\"\n) -&gt; EncodingResult:\n    \"\"\"\n    Encode document to images with optional encryption.\n\n    Args:\n        file_path: Path to document to encode\n        output_dir: Directory to save encoded images\n\n    Returns:\n        EncodingResult with metadata and image information\n\n    Raises:\n        FileNotFoundError: If input file doesn't exist\n        ValueError: If file cannot be processed\n    \"\"\"\n    file_path = Path(file_path)\n    output_dir = Path(output_dir)\n    output_dir.mkdir(exist_ok=True)\n\n    # Step 1: Process document\n    document_data, file_metadata = self._process_document(file_path)\n\n    # Step 2: Optionally encrypt data\n    if self.encryption_key:\n        encrypted_data = self._xor_encrypt_decrypt(document_data, self.encryption_key)\n    else:\n        encrypted_data = document_data\n\n    # Step 3: Create chunks\n    chunks = self._create_chunks(encrypted_data)\n\n    # Step 4: Generate image names\n    chunk_names = await self._generate_image_names(len(chunks))\n\n    # Create metadata image name based on document name\n    document_name = file_path.stem  # Get filename without extension\n    metadata_image_name = f\"{document_name}_metadata.png\"\n\n    # Step 5: Create chunk images\n    chunk_infos = []\n    chunk_images = []\n\n    for i, (chunk_data, filename) in enumerate(zip(chunks, chunk_names)):\n        chunk_hash = self._calculate_hash(chunk_data)\n        image_path = output_dir / filename\n\n        self._encode_data_to_image(chunk_data, image_path)\n\n        chunk_infos.append(\n            ChunkInfo(chunk_id=i, image_name=filename, data_bytes=len(chunk_data), chunk_hash=chunk_hash)\n        )\n        chunk_images.append(filename)\n\n    # Step 6: Create metadata\n    metadata = self._create_metadata(file_metadata, chunk_infos, encrypted_data)\n\n    # Step 7: Create metadata image\n    metadata_path = output_dir / metadata_image_name\n    metadata_json = json.dumps(metadata, indent=2).encode(\"utf-8\")\n\n    self._encode_data_to_image(metadata_json, metadata_path)\n\n    return EncodingResult(\n        metadata_image=metadata_image_name,\n        chunk_images=chunk_images,\n        total_size=len(encrypted_data),\n        chunk_count=len(chunks),\n    )\n</code></pre>"},{"location":"reference/ciphergeist/encoders/pixelator/#ciphergeist.encoders.pixelator.main","title":"<code>main()</code>  <code>async</code>","text":"<p>Example usage of Pixelator.</p> Source code in <code>src/ciphergeist/encoders/pixelator.py</code> <pre><code>async def main() -&gt; None:\n    \"\"\"Example usage of Pixelator.\"\"\"\n    import shutil\n\n    output_dir = Path(\"output/pixelatortest\")\n\n    # Clear the output directory first for easier testing\n    if output_dir.exists():\n        shutil.rmtree(output_dir)\n    output_dir.mkdir(parents=True, exist_ok=True)\n\n    async with Pixelator() as pixelator:\n        result = await pixelator.encode_document(\"src/ciphergeist/books/dracula.txt\", output_dir)\n        print(f\"Encoded to {result.chunk_count} images\")\n        print(f\"Metadata image: {result.metadata_image}\")\n        print(f\"Output directory: {output_dir}\")\n        print(f\"Total size: {result.total_size} bytes\")\n</code></pre>"},{"location":"reference/ciphergeist/encrypters/","title":"Index","text":""},{"location":"reference/ciphergeist/encrypters/substitutor/","title":"substitutor","text":"<p>Substitution cipher implementation with frequency analysis-based decryption.</p> <p>This module provides tools for creating and breaking substitution ciphers, where each letter of the alphabet is consistently replaced with another letter.</p>"},{"location":"reference/ciphergeist/encrypters/substitutor/#ciphergeist.encrypters.substitutor.SubstitutionGuess","title":"<code>SubstitutionGuess</code>  <code>dataclass</code>","text":"<p>Represents a guess for a substitution cipher key and resulting plaintext.</p> Source code in <code>src/ciphergeist/encrypters/substitutor.py</code> <pre><code>@dataclass(order=True)\nclass SubstitutionGuess:\n    \"\"\"Represents a guess for a substitution cipher key and resulting plaintext.\"\"\"\n\n    score: float\n    cipher_map: dict[str, str]\n    ciphertext: str\n    plaintext: str\n\n    def __init__(self, ciphertext: str, cipher_map: dict[str, str], is_empty: bool = False):\n        self.ciphertext = ciphertext\n        self.cipher_map = cipher_map.copy()\n        if is_empty:\n            self.plaintext = \"\"\n            self.score = float(\"inf\")\n            return\n        self.plaintext = apply_substitution_cipher(ciphertext, cipher_map)\n        self.score = score_substitution_text(self.plaintext)\n\n    @classmethod\n    def empty(cls) -&gt; \"SubstitutionGuess\":\n        \"\"\"Create an empty guess with infinite score for comparison.\"\"\"\n        return cls(\"\", {}, is_empty=True)\n</code></pre>"},{"location":"reference/ciphergeist/encrypters/substitutor/#ciphergeist.encrypters.substitutor.SubstitutionGuess.empty","title":"<code>empty()</code>  <code>classmethod</code>","text":"<p>Create an empty guess with infinite score for comparison.</p> Source code in <code>src/ciphergeist/encrypters/substitutor.py</code> <pre><code>@classmethod\ndef empty(cls) -&gt; \"SubstitutionGuess\":\n    \"\"\"Create an empty guess with infinite score for comparison.\"\"\"\n    return cls(\"\", {}, is_empty=True)\n</code></pre>"},{"location":"reference/ciphergeist/encrypters/substitutor/#ciphergeist.encrypters.substitutor.apply_substitution_cipher","title":"<code>apply_substitution_cipher(text, cipher_map)</code>","text":"<p>Apply a substitution cipher to text using the given cipher map.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>The text to encrypt/decrypt.</p> required <code>cipher_map</code> <code>dict[str, str]</code> <p>Mapping from original to substituted characters.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The text with substitutions applied. Same length as input.</p> Source code in <code>src/ciphergeist/encrypters/substitutor.py</code> <pre><code>def apply_substitution_cipher(text: str, cipher_map: dict[str, str]) -&gt; str:\n    \"\"\"Apply a substitution cipher to text using the given cipher map.\n\n    Args:\n        text (str): The text to encrypt/decrypt.\n        cipher_map (dict[str, str]): Mapping from original to substituted characters.\n\n    Returns:\n        str: The text with substitutions applied. Same length as input.\n    \"\"\"\n    result = \"\"\n    for char in text:\n        if char in cipher_map:\n            result += cipher_map[char]\n        else:\n            result += char\n    return result\n</code></pre>"},{"location":"reference/ciphergeist/encrypters/substitutor/#ciphergeist.encrypters.substitutor.frequency_analysis_attack","title":"<code>frequency_analysis_attack(ciphertext)</code>","text":"<p>Attempt to break a substitution cipher using frequency analysis.</p> <p>Analyzes the frequency of letters in the ciphertext and maps them to the most common letters in English based on expected frequencies.</p> <p>Parameters:</p> Name Type Description Default <code>ciphertext</code> <code>str</code> <p>The ciphertext to analyze.</p> required <p>Returns:</p> Name Type Description <code>SubstitutionGuess</code> <code>SubstitutionGuess</code> <p>The best guess for the substitution cipher.</p> Source code in <code>src/ciphergeist/encrypters/substitutor.py</code> <pre><code>def frequency_analysis_attack(ciphertext: str) -&gt; SubstitutionGuess:\n    \"\"\"Attempt to break a substitution cipher using frequency analysis.\n\n    Analyzes the frequency of letters in the ciphertext and maps them\n    to the most common letters in English based on expected frequencies.\n\n    Args:\n        ciphertext (str): The ciphertext to analyze.\n\n    Returns:\n        SubstitutionGuess: The best guess for the substitution cipher.\n    \"\"\"\n    cipher_letters = \"\".join(c.lower() for c in ciphertext if c.isalpha())\n\n    if len(cipher_letters) == 0:\n        return SubstitutionGuess.empty()\n\n    cipher_map = _create_frequency_mapping(cipher_letters)\n    return SubstitutionGuess(ciphertext, cipher_map)\n</code></pre>"},{"location":"reference/ciphergeist/encrypters/substitutor/#ciphergeist.encrypters.substitutor.reverse_cipher_map","title":"<code>reverse_cipher_map(cipher_map)</code>","text":"<p>Reverse a cipher map to create the decryption key.</p> <p>Parameters:</p> Name Type Description Default <code>cipher_map</code> <code>dict[str, str]</code> <p>The original cipher map.</p> required <p>Returns:</p> Type Description <code>dict[str, str]</code> <p>dict[str, str]: The reversed cipher map for decryption.</p> Source code in <code>src/ciphergeist/encrypters/substitutor.py</code> <pre><code>def reverse_cipher_map(cipher_map: dict[str, str]) -&gt; dict[str, str]:\n    \"\"\"Reverse a cipher map to create the decryption key.\n\n    Args:\n        cipher_map (dict[str, str]): The original cipher map.\n\n    Returns:\n        dict[str, str]: The reversed cipher map for decryption.\n    \"\"\"\n    return {v: k for k, v in cipher_map.items()}\n</code></pre>"},{"location":"reference/ciphergeist/encrypters/substitutor/#ciphergeist.encrypters.substitutor.score_substitution_text","title":"<code>score_substitution_text(text)</code>","text":"<p>Score a text string based on letter frequency analysis.</p> <p>Compares the frequency of letters in the text against the expected frequency distribution of lowercase letters in English text.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>The text string to score.</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>The score representing the difference in letter frequencies. A lower score indicates a closer match to expected frequencies.</p> Source code in <code>src/ciphergeist/encrypters/substitutor.py</code> <pre><code>def score_substitution_text(text: str) -&gt; float:\n    \"\"\"Score a text string based on letter frequency analysis.\n\n    Compares the frequency of letters in the text against the expected\n    frequency distribution of lowercase letters in English text.\n\n    Args:\n        text (str): The text string to score.\n\n    Returns:\n        float: The score representing the difference in letter frequencies.\n            A lower score indicates a closer match to expected frequencies.\n    \"\"\"\n    if len(text) == 0:\n        return float(\"inf\")\n\n    text_lower = \"\".join(c.lower() for c in text if c.isalpha())\n    if len(text_lower) == 0:\n        return float(\"inf\")\n\n    counts_text: Counter[str] = Counter()\n    for letter in lowercase_frequencies:\n        counts_text[letter] = text_lower.count(letter)\n\n    total = sum(counts_text.values())\n    if total == 0:\n        return float(\"inf\")\n\n    frequencies_text = {letter: counts_text[letter] / total for letter in lowercase_frequencies}\n    errors = {abs(lowercase_frequencies[letter] - frequencies_text[letter]) for letter in lowercase_frequencies}\n    return sum(errors)\n</code></pre>"},{"location":"reference/ciphergeist/encrypters/xorxer/","title":"xorxer","text":""},{"location":"reference/ciphergeist/encrypters/xorxer/#ciphergeist.encrypters.xorxer.Guess","title":"<code>Guess</code>  <code>dataclass</code>","text":"Source code in <code>src/ciphergeist/encrypters/xorxer.py</code> <pre><code>@dataclass(order=True)\nclass Guess:\n    score: float\n    key: int\n    ciphertext: bytes\n    plaintext: bytes\n\n    def __init__(self, ciphertext: bytes, key: int, is_empty: bool = False):\n        self.ciphertext = ciphertext\n        self.key = key\n        if is_empty:\n            self.plaintext = b\"\"\n            self.score = float(\"inf\")\n            return\n        self.plaintext = single_byte_xor(ciphertext, key)\n        self.score = score_text(self.plaintext)\n\n    @classmethod\n    def empty(cls) -&gt; \"Guess\":\n        \"\"\"Create an empty guess with infinite score for comparison.\"\"\"\n        return cls(b\"\", 0, is_empty=True)\n</code></pre>"},{"location":"reference/ciphergeist/encrypters/xorxer/#ciphergeist.encrypters.xorxer.Guess.empty","title":"<code>empty()</code>  <code>classmethod</code>","text":"<p>Create an empty guess with infinite score for comparison.</p> Source code in <code>src/ciphergeist/encrypters/xorxer.py</code> <pre><code>@classmethod\ndef empty(cls) -&gt; \"Guess\":\n    \"\"\"Create an empty guess with infinite score for comparison.\"\"\"\n    return cls(b\"\", 0, is_empty=True)\n</code></pre>"},{"location":"reference/ciphergeist/encrypters/xorxer/#ciphergeist.encrypters.xorxer.fixed_xor","title":"<code>fixed_xor(a, b)</code>","text":"<p>Perform a fixed XOR operation on two byte strings.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>bytes</code> <p>The first byte string.</p> required <code>b</code> <code>bytes</code> <p>The second byte string.</p> required <p>Returns:</p> Name Type Description <code>bytes</code> <code>bytes</code> <p>The result of the XOR operation.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the input byte strings are of different lengths.</p> Source code in <code>src/ciphergeist/encrypters/xorxer.py</code> <pre><code>def fixed_xor(a: bytes, b: bytes) -&gt; bytes:\n    \"\"\"Perform a fixed XOR operation on two byte strings.\n\n    Args:\n        a (bytes): The first byte string.\n        b (bytes): The second byte string.\n\n    Returns:\n        bytes: The result of the XOR operation.\n\n    Raises:\n        ValueError: If the input byte strings are of different lengths.\n    \"\"\"\n    if len(a) != len(b):\n        raise ValueError(\"Input must be of the same length.\")\n    return bytes(x ^ y for x, y in zip(a, b))\n</code></pre>"},{"location":"reference/ciphergeist/encrypters/xorxer/#ciphergeist.encrypters.xorxer.guess_single_key_xor","title":"<code>guess_single_key_xor(ciphertext)</code>","text":"<p>Guess the single-byte XOR key for a given ciphertext.</p> <p>Iterates through all possible single-byte keys (0-255) and scores the resulting plaintext using letter frequency analysis.</p> <p>Parameters:</p> Name Type Description Default <code>ciphertext</code> <code>bytes</code> <p>The ciphertext to analyze.</p> required <p>Returns:</p> Name Type Description <code>Guess</code> <code>Guess</code> <p>The best guess containing the key, plaintext, and score.</p> Source code in <code>src/ciphergeist/encrypters/xorxer.py</code> <pre><code>def guess_single_key_xor(ciphertext: bytes) -&gt; Guess:\n    \"\"\"Guess the single-byte XOR key for a given ciphertext.\n\n    Iterates through all possible single-byte keys (0-255)\n    and scores the resulting plaintext using letter frequency analysis.\n\n    Args:\n        ciphertext (bytes): The ciphertext to analyze.\n\n    Returns:\n        Guess: The best guess containing the key, plaintext, and score.\n    \"\"\"\n    best_guess = Guess.empty()\n    for key in range(256):\n        current_guess = Guess(ciphertext, key)\n        best_guess = min(best_guess, current_guess)\n    return best_guess\n</code></pre>"},{"location":"reference/ciphergeist/encrypters/xorxer/#ciphergeist.encrypters.xorxer.quick_guess_single_byte_xor","title":"<code>quick_guess_single_byte_xor(ciphertext)</code>","text":"<p>Quickly guess a single-byte XOR key.</p> <p>Using letter frequency analysis. Asuming the most common byte in the ciphertext corresponds to the most common letter in English text (e.g., 'e', 't', 'a').</p> <p>Parameters:</p> Name Type Description Default <code>ciphertext</code> <code>bytes</code> <p>The ciphertext to analyze.</p> required <p>Returns:</p> Type Description <code>Guess</code> <p>list[tuple[float, int, bytes]]: A sorted list of tuples containing the score, key, and plaintext for each candidate key.</p> Source code in <code>src/ciphergeist/encrypters/xorxer.py</code> <pre><code>def quick_guess_single_byte_xor(ciphertext: bytes) -&gt; Guess:\n    \"\"\"Quickly guess a single-byte XOR key.\n\n    Using letter frequency analysis.\n    Asuming the most common byte in the ciphertext corresponds to\n    the most common letter in English text (e.g., 'e', 't', 'a').\n\n    Args:\n        ciphertext (bytes): The ciphertext to analyze.\n\n    Returns:\n        list[tuple[float, int, bytes]]: A sorted list of tuples containing the score,\n            key, and plaintext for each candidate key.\n    \"\"\"\n    frequencies = Counter(ciphertext)\n    most_common_byte = frequencies.most_common(1)[0][0]\n    common_chars = set(\" etaoinshrdlu\")\n    best_guess = Guess.empty()\n    for char in common_chars:\n        current_guess = Guess(ciphertext, most_common_byte ^ ord(char))\n        best_guess = min(best_guess, current_guess)\n    return best_guess\n</code></pre>"},{"location":"reference/ciphergeist/encrypters/xorxer/#ciphergeist.encrypters.xorxer.score_text","title":"<code>score_text(text)</code>","text":"<p>Score a byte string based on letter frequency analysis.</p> <p>This function compares the frequency of letters in the text against a predefined frequency distribution of lowercase letters in English text.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>bytes</code> <p>The byte string to score.</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>The score representing the difference in letter frequencies. A lower score indicates a closer match to expected frequencies.</p> Source code in <code>src/ciphergeist/encrypters/xorxer.py</code> <pre><code>def score_text(text: bytes) -&gt; float:\n    \"\"\"Score a byte string based on letter frequency analysis.\n\n    This function compares the frequency of letters in the text against\n    a predefined frequency distribution of lowercase letters in English text.\n\n    Args:\n        text (bytes): The byte string to score.\n\n    Returns:\n        float: The score representing the difference in letter frequencies.\n            A lower score indicates a closer match to expected frequencies.\n    \"\"\"\n    if len(text) == 0:\n        raise ValueError(\"Input text cannot be empty\")\n    counts_text: Counter[str] = Counter()\n    for letter in lowercase_frequencies:\n        counts_text[letter] = text.count(letter.encode())\n    total = sum(counts_text.values())\n    if total == 0:\n        return float(\"inf\")\n\n    frequencies_text = {letter: counts_text[letter] / total for letter in lowercase_frequencies}\n    errors = {abs(lowercase_frequencies[letter] - frequencies_text[letter]) for letter in lowercase_frequencies}\n    score = sum(errors)\n    return score\n</code></pre>"},{"location":"reference/ciphergeist/encrypters/xorxer/#ciphergeist.encrypters.xorxer.single_byte_xor","title":"<code>single_byte_xor(input_bytes, key)</code>","text":"<p>Perform a single-byte XOR operation on a byte string.</p> <p>Parameters:</p> Name Type Description Default <code>input_bytes</code> <code>bytes</code> <p>The byte string to be XORed.</p> required <code>key</code> <code>int</code> <p>The single-byte key to XOR with (0-255).</p> required <p>Returns:</p> Name Type Description <code>bytes</code> <code>bytes</code> <p>The result of the XOR operation.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the key is not an integer in the range 0-255.</p> Source code in <code>src/ciphergeist/encrypters/xorxer.py</code> <pre><code>def single_byte_xor(input_bytes: bytes, key: int) -&gt; bytes:\n    \"\"\"Perform a single-byte XOR operation on a byte string.\n\n    Args:\n        input_bytes (bytes): The byte string to be XORed.\n        key (int): The single-byte key to XOR with (0-255).\n\n    Returns:\n        bytes: The result of the XOR operation.\n\n    Raises:\n        ValueError: If the key is not an integer in the range 0-255.\n    \"\"\"\n    if not (0 &lt;= key &lt;= 255):\n        raise ValueError(\"Key must be int (0-255).\")\n    return bytes(b ^ key for b in input_bytes)\n</code></pre>"},{"location":"reference/ciphergeist/frequencies/","title":"Index","text":""},{"location":"reference/ciphergeist/frequencies/calculate_frequenzies/","title":"calculate_frequenzies","text":""},{"location":"reference/ciphergeist/frequencies/calculate_frequenzies/#ciphergeist.frequencies.calculate_frequenzies.calculate_and_save_frequencies","title":"<code>calculate_and_save_frequencies(books_dir='src/ciphergeist/books', output_dir='src/ciphergeist/frequencies')</code>","text":"<p>Calculate letter frequencies from text files in a specified directory and save them as JSON files.</p> <p>Parameters:</p> Name Type Description Default <code>books_dir</code> <code>str</code> <p>Directory containing text files of books.</p> <code>'src/ciphergeist/books'</code> <code>output_dir</code> <code>str</code> <p>Directory where the frequency JSON files will be saved.</p> <code>'src/ciphergeist/frequencies'</code> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>src/ciphergeist/frequencies/calculate_frequenzies.py</code> <pre><code>def calculate_and_save_frequencies(\n    books_dir: str = \"src/ciphergeist/books\", output_dir: str = \"src/ciphergeist/frequencies\"\n) -&gt; None:\n    \"\"\"Calculate letter frequencies from text files in a specified directory and save them as JSON files.\n\n    Args:\n        books_dir (str): Directory containing text files of books.\n        output_dir (str): Directory where the frequency JSON files will be saved.\n\n    Returns:\n        None\n    \"\"\"\n    lowercase_counts: Counter[str] = Counter()\n    uppercase_counts: Counter[str] = Counter()\n    mixed_counts: Counter[str] = Counter()\n    total_letters: int = 0\n\n    for filename in os.listdir(books_dir):\n        if filename.endswith(\".txt\"):\n            filepath = os.path.join(books_dir, filename)\n            with open(filepath, encoding=\"utf-8\") as f:\n                text = f.read()\n                total_letters += len(text)\n                for char in text:\n                    if char in string.ascii_lowercase:\n                        lowercase_counts[char] += 1\n                        mixed_counts[char] += 1\n                    elif char in string.ascii_uppercase:\n                        uppercase_counts[char] += 1\n                        mixed_counts[char] += 1\n\n    def normalize_counts(counts: Counter[str]) -&gt; dict[str, float]:\n        total = sum(counts.values())\n        return {char: count / total for char, count in counts.items()}\n\n    lowercase_frequencies = normalize_counts(lowercase_counts)\n    uppercase_frequencies = normalize_counts(uppercase_counts)\n    mixed_frequencies = normalize_counts(mixed_counts)\n    # sort them by frequency\n    lowercase_frequencies = dict(sorted(lowercase_frequencies.items(), key=lambda item: item[1], reverse=True))\n    uppercase_frequencies = dict(sorted(uppercase_frequencies.items(), key=lambda item: item[1], reverse=True))\n    mixed_frequencies = dict(sorted(mixed_frequencies.items(), key=lambda item: item[1], reverse=True))\n\n    os.makedirs(output_dir, exist_ok=True)  # Ensure the output directory exists\n\n    def save_json(data: dict[str, float], filename: str) -&gt; None:\n        filepath = os.path.join(output_dir, filename)\n        with open(filepath, \"w\", encoding=\"utf-8\") as f:\n            json.dump(data, f, indent=4)\n\n    def save_as_python_dictionary(data: dict[str, float], filename: str) -&gt; None:\n        filepath = os.path.join(output_dir, filename)\n        with open(filepath, \"w\", encoding=\"utf-8\") as f:\n            f.write(f\"letter_frequencies = {data}\")\n\n    save_json(lowercase_frequencies, \"lowercase_frequencies.json\")\n    save_as_python_dictionary(lowercase_frequencies, \"lowercase_frequencies.py\")\n    save_json(uppercase_frequencies, \"uppercase_frequencies.json\")\n    save_as_python_dictionary(uppercase_frequencies, \"uppercase_frequencies.py\")\n    save_json(mixed_frequencies, \"mixed_frequencies.json\")\n    save_as_python_dictionary(mixed_frequencies, \"mixed_frequencies.py\")\n\n    print(f\"Processed {total_letters} letters from books in {books_dir}\")\n    print(f\"Frequencies saved to {output_dir}\")\n</code></pre>"},{"location":"reference/ciphergeist/frequencies/lowercase_frequencies/","title":"lowercase_frequencies","text":""},{"location":"reference/ciphergeist/frequencies/mixed_frequencies/","title":"mixed_frequencies","text":""},{"location":"reference/ciphergeist/frequencies/uppercase_frequencies/","title":"uppercase_frequencies","text":""},{"location":"shc/crypto/office-encryption/","title":"office encryption","text":""},{"location":"shc/crypto/office-encryption/#description","title":"Description","text":"<p>I heard about this nation state actor I'm not sure why actors would attack companies but we need encryption to secure our systems. Please add the encryption program I made to every software we had so we are secure!</p>"},{"location":"shc/crypto/office-encryption/#author","title":"Author","text":"<p>xnull</p> <p>cyphertext: <pre><code>swo2024{jytmm_ruvs_opgbzu_mum}\n</code></pre></p> <p>cypher map: <pre><code>{'a': 'k', 'b': 'n', 'c': 'o', 'd': 'r', 'e': 'v', 'f': 'q', 'g': 'i', 'h': 'w', 'i': 'x', 'j': 'd', 'k': 'h', 'l': 'm', 'm': 'l', 'n': 'y', 'o': 'u', 'p': 'b', 'q': 'f', 'r': 'p', 's': 's', 't': 'z', 'u': 't', 'v': 'a', 'w': 'c', 'x': 'j', 'y': 'g', 'z': 'e'}\n</code></pre></p> <p>encryption code: <pre><code>from random import shuffle\nfrom collections import Counter\n\n\ndef generate_substitution_cipher(text):\n    alphabet = \"abcdefghijklmnopqrstuvwxyz\"\n    shuffled_alphabet = list(alphabet)\n    shuffle(shuffled_alphabet)\n    cipher_map = {\n        original: substituted\n        for original, substituted in zip(alphabet, shuffled_alphabet)\n    }\n\n    encrypted_text = \"\"\n    for char in text:\n        if char.lower() in cipher_map:\n            encrypted_char = cipher_map[char.lower()]\n            if char.isupper():\n                encrypted_char = encrypted_char.upper()\n            encrypted_text += encrypted_char\n        else:\n            encrypted_text += char\n\n    return encrypted_text, cipher_map\n\n\ntext = \"shc2024{fake_flag}\"\n\nencrypted_text, cipher_map = generate_substitution_cipher(text)\n\nprint(encrypted_text, cipher_map)\n</code></pre></p>"},{"location":"shc/crypto/office-encryption/#solution","title":"Solution","text":"<pre><code>def reverse_cipher_map(cipher_map: dict[str, str]) -&gt; dict[str, str]:\n    \"\"\"Reverse a cipher map to create the decryption key.\n\n    Args:\n        cipher_map (dict[str, str]): The original cipher map.\n\n    Returns:\n        dict[str, str]: The reversed cipher map for decryption.\n    \"\"\"\n    return {v: k for k, v in cipher_map.items()}\n\n\ndef apply_substitution_cipher(text: str, cipher_map: dict[str, str]) -&gt; str:\n    \"\"\"Apply a substitution cipher to text using the given cipher map.\n\n    Args:\n        text (str): The text to encrypt/decrypt.\n        cipher_map (dict[str, str]): Mapping from original to substituted characters.\n\n    Returns:\n        str: The text with substitutions applied. Same length as input.\n    \"\"\"\n    result = \"\"\n    for char in text:\n        if char in cipher_map:\n            result += cipher_map[char]\n        else:\n            result += char\n    return result\n\n\nreversed_map = reverse_cipher_map(known_cipher_map)\ndecrypted = apply_substitution_cipher(ciphertext, reversed_map)\nprint(f\"Decrypted: {decrypted}\")\n</code></pre> <p>Decrypted: shc2024{xnull_does_crypto_lol}</p>"},{"location":"shc/crypto/really_secure_application/","title":"Description","text":"<p>We recently had an intern around before the crisis happened. He learned about cryptography and encrypted the password for our coffee machine???</p> <p>We can't get through this without coffee.</p> <p>Author Coderion</p> <p>Public modulus (n): 1186029292037952909983792432306452587425266074685148559256411524118533884795954832993947356308189843827916747393770934033391200656633881903962557992375311329821223845429093776689672634207483637282457856395284891548748666784553146529707500135533133296584880911894111872112018935683414189955943902732488471774953</p> <p>Public exponent (e): 65537</p> <p>Encrypted flag: 733568336222790589470096969949196690400886881122508612017162580799729948344126319987475331014669434677564792251353760238087218803592587521385878004071493183548939254573853401155722047457350634791379651022516512709399603944845196902930993851922578027579933013748262257897144604228176365756268938687669643000231 \u00b4\u00b4\u00b4</p>"},{"location":"shc/crypto/really_secure_application/#solution","title":"Solution","text":"<p>This RSA challenge has a critical weakness: one of the prime factors is extremely small.</p> <p>Vulnerability: The modulus <code>n</code> can be factored because it contains the small prime <code>7</code>.</p> <p>Attack Method: Query FactorDB.com for known factorizations:</p> <pre><code>curl -X GET https://factordb.com/api?query=1186029292037952909983792432306452587425266074685148559256411524118533884795954832993947356308189843827916747393770934033391200656633881903962557992375311329821223845429093776689672634207483637282457856395284891548748666784553146529707500135533133296584880911894111872112018935683414189955943902732488471774953\n</code></pre> <p>Returns: <pre><code>{\"id\":1100000007513254511,\"status\":\"FF\",\"factors\":[[\"7\",1],[\"169432756005421844283398918900921798203609439240735508465201646302647697827993547570563908044027120546845249627681562004770171522376268843423222570339330189974460549347013396669953233458211948183208265199326413078392666683507592361386785733647590470940697273127730267444574133669059169993706271818926924539279\",1]]}\n</code></pre></p> <p>With <code>p = 7</code> and <code>q = &lt;large_number&gt;</code>, we can calculate the private key and decrypt the message.</p> <p>Decryption Steps: 1. Calculate <code>\u03c6(n) = (p-1)(q-1) = 6 \u00d7 (q-1)</code> 2. Calculate private key: <code>d = e^(-1) mod \u03c6(n)</code> 3. Decrypt: <code>message = ciphertext^d mod n</code> 4. Convert to text: <code>long_to_bytes(message)</code></p> <p>Flag: <code>SCD{w34k_r54_pr1m3s_1fed2fea}</code></p>"}]}